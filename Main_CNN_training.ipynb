{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Here, we begin by installing the required libraries."
      ],
      "metadata": {
        "id": "V0Jx2O8H3tN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VgisTe2mjRvS",
        "outputId": "40403b55-1352-4248-f5a0-9cbccd7a6afa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.27-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.1/74.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler"
                ]
              },
              "id": "c8c08b7b0a184209a870166e7f76bfed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import display\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator, colors"
      ],
      "metadata": {
        "id": "hHunm33lgjem"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"lRIgGm3WjzsZyY4OcgnE\")\n",
        "project = rf.workspace(\"chinh\").project(\"person_camera_security1\")\n",
        "version = project.version(20)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "FCQQSBPlgmbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9ae3e8-2f58-4caa-c955-76a730a6ddb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.2.2, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in person_camera_security1-20 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 203764/203764 [00:05<00:00, 36820.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to person_camera_security1-20 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6328/6328 [00:01<00:00, 4386.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We do transfer learning on the pretrained general purpose YOLOv8 model nano. This model can detect 80 different classes, the person class is the interest to us. Our aim is to improve its accuracy in detecting persons. So, we use the dataset from ROBOFLOW that is specifically data from webcams in order to do this transfer learning.\n",
        "\n",
        "###Note that as per the YOLOv8 documentation, data augmentation is being done inside the library by default, as well as other measures to prevent overfitting. It also uses adam optimizer in updating the weights.\n",
        "\n",
        "### Also note that this training is done using the local GPU resources, and it is done on the NANO model because it is the smallest one and thus the fastest. This is important in order to be able to export the trained model later into the project code which will run on Raspberry pi."
      ],
      "metadata": {
        "id": "im6MaeIe2qAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Use the model\n",
        "model.train(data=\"/content/person_camera_security1-20/data.yaml\", epochs=100)  # train the model\n",
        "metrics = model.val()  # evaluate model performance on the validation set\n",
        "#results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "path = model.export(format=\"onnx\")  # export the model to ONNX format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys3TRiAuyfSv",
        "outputId": "7687f74b-972a-4d24-aa59-f965265ed219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.2 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/person_camera_security1-20/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 17.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/person_camera_security1-20/train/labels... 2500 images, 42 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [00:01<00:00, 1613.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/person_camera_security1-20/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/person_camera_security1-20/valid/labels... 436 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [00:00<00:00, 1030.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/person_camera_security1-20/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      2.52G       1.51      2.165      1.248         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:09<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.777       0.45      0.508      0.333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      2.26G      1.417       1.35      1.211         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.616      0.436       0.46      0.259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      2.27G      1.358      1.188      1.195         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.58       0.37      0.379      0.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      2.25G      1.316      1.089      1.183         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.736      0.371      0.381      0.235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      2.25G      1.272      1.009      1.174         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.843      0.367      0.495      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      2.35G      1.245     0.9494      1.157         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.806      0.331      0.417      0.288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      2.23G      1.232     0.8978      1.157         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.613      0.379      0.394      0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      2.34G      1.194     0.8529      1.134         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.717      0.455      0.401      0.257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      2.32G      1.172     0.8214      1.126         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.448      0.429      0.465      0.335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      2.34G      1.173     0.7976      1.128          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:00<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.863       0.37      0.435      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      2.33G      1.148     0.7687      1.112         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:02<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.37      0.506      0.442       0.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      2.26G      1.125     0.7487      1.099         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:03<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.793      0.416      0.462      0.291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      2.32G      1.131     0.7484        1.1         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:01<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.474      0.431      0.439      0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      2.33G      1.108      0.723       1.09         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:03<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.833      0.391      0.461       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      2.24G      1.098      0.716      1.092          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:01<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.751      0.485      0.495      0.312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      2.24G      1.064     0.7005      1.078          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:01<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.759      0.349      0.425        0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      2.22G      1.065     0.6858      1.079         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:06<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.735      0.344      0.462      0.322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      2.25G      1.063     0.6809      1.082         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:01<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.744       0.49      0.509      0.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      2.34G      1.038     0.6603      1.068         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:08<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.675      0.416      0.468      0.313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      2.25G      1.038     0.6504      1.064          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:02<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.529      0.472       0.47      0.322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      2.32G      1.031      0.641      1.056         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.753      0.497      0.535      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      2.32G      1.044       0.64      1.061         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.73      0.549      0.533      0.327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      2.34G      1.021     0.6355      1.058         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.634      0.609       0.52      0.335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      2.34G     0.9937     0.6191      1.043         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.502      0.531      0.505      0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      2.32G     0.9823     0.6067      1.042         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.64      0.568      0.523      0.339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      2.22G      1.005     0.6032      1.049         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.622      0.485      0.492      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      2.32G     0.9819     0.5945       1.04         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.627      0.464      0.478      0.333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      2.32G     0.9718     0.5912      1.037         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.455      0.542      0.492      0.332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      2.26G      0.971     0.5871      1.037          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.564      0.496      0.506      0.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      2.32G     0.9618     0.5867      1.036         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.799      0.526      0.562       0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      2.25G     0.9389     0.5766      1.019         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.593      0.601      0.528      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      2.34G     0.9441     0.5768      1.024         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.693       0.56      0.526      0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      2.33G     0.9439     0.5706      1.023         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.708      0.543       0.51      0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      2.35G     0.9384     0.5706      1.024         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.447      0.573       0.51      0.326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      2.27G     0.9285     0.5616      1.019         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.774      0.495      0.534      0.373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      2.31G     0.9199     0.5508      1.014         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.469      0.519      0.498      0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      2.26G     0.9121     0.5507      1.007         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.78      0.461      0.516      0.349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      2.33G     0.9002     0.5434      1.006         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.777       0.51      0.546      0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      2.32G     0.8992     0.5478      1.004         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.707      0.462      0.525      0.377\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      2.31G     0.8829     0.5344     0.9978         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.555      0.542      0.519      0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      2.25G       0.89     0.5303     0.9959         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.617      0.514      0.511      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      2.35G     0.8798     0.5232     0.9959         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.559      0.508      0.516      0.355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      2.35G     0.8723     0.5206     0.9913         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.516      0.475      0.517      0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      2.31G     0.8807     0.5245     0.9955         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.67      0.458      0.498       0.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      2.32G     0.8599     0.5115      0.986         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.754      0.424      0.517      0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      2.35G     0.8804     0.5168     0.9922         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.548      0.505      0.536      0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      2.32G     0.8518     0.4999     0.9832         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.634      0.519      0.514      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      2.32G     0.8545     0.5092     0.9844         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.653      0.424      0.473      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      2.19G     0.8475     0.5083     0.9839         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.834      0.496      0.566      0.391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      2.32G     0.8427     0.4951     0.9768         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.634      0.534      0.531      0.381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      2.24G     0.8395     0.5002     0.9793         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.892      0.418      0.502       0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      2.34G     0.8308     0.4942     0.9778         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.64      0.489       0.48      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      2.32G      0.824     0.4892     0.9733         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.659      0.438       0.52      0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      2.35G      0.827     0.4929     0.9701         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.564      0.495      0.494      0.367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      2.33G     0.8251      0.489     0.9688         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.597      0.528      0.513      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      2.34G     0.8168     0.4784     0.9698         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.456      0.547      0.519      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      2.32G     0.8157     0.4844      0.967         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.731      0.456      0.523      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      2.25G     0.8064     0.4754     0.9661         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.685      0.423      0.495      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      2.32G     0.8057     0.4751     0.9642         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.825      0.401       0.49      0.346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      2.33G     0.7896     0.4723     0.9583         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.671      0.489      0.505      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100      2.25G     0.7807     0.4632     0.9568         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.621      0.428      0.491      0.351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      2.27G     0.7923     0.4679     0.9591         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.651      0.436      0.485      0.353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      2.33G     0.7791     0.4599     0.9558         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.635      0.514      0.494       0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      2.34G      0.777       0.46     0.9546         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.502       0.43      0.472      0.345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      2.37G     0.7739     0.4585     0.9473         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.491       0.52      0.509      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      2.32G     0.7645     0.4574     0.9503         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.644      0.491      0.507      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      2.32G       0.78     0.4626     0.9624         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.643      0.483      0.512      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      2.32G     0.7604     0.4519     0.9499         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.474      0.359      0.466      0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      2.33G     0.7618     0.4482     0.9483         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.598      0.421      0.427      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      2.26G     0.7562     0.4427     0.9446         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.659      0.424      0.457      0.352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      2.32G     0.7462     0.4452     0.9444         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.55      0.448      0.452      0.344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      2.21G      0.745     0.4431     0.9466         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.731      0.501       0.53      0.364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      2.23G     0.7373     0.4389     0.9432         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.669       0.51      0.529      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      2.32G     0.7366     0.4351     0.9399         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.663      0.517      0.493      0.366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      2.36G     0.7348     0.4308     0.9394         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.689      0.434      0.513       0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      2.35G     0.7462     0.4384     0.9411         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.685      0.456      0.516      0.369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      2.26G     0.7336     0.4341     0.9391         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.827      0.487      0.549      0.391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      2.35G     0.7248     0.4262     0.9328         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.559      0.513      0.493      0.361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      2.23G      0.728     0.4303      0.937         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.668      0.428      0.485      0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      2.24G     0.7152      0.422     0.9321         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.602      0.445      0.473       0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      2.23G     0.7149     0.4218     0.9329         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.65      0.495      0.517      0.361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      2.35G     0.7125     0.4209     0.9266         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.686      0.482      0.493      0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      2.24G     0.6998     0.4138     0.9266         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.655      0.481      0.508      0.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      2.26G     0.7014     0.4169      0.928          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.74      0.488      0.513      0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      2.28G     0.6984     0.4181      0.928         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.645      0.505      0.507      0.368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      2.24G       0.71     0.4198     0.9297         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.56      0.571      0.528      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      2.23G     0.6956     0.4137      0.925         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.524      0.555       0.49      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      2.22G     0.6804     0.4001     0.9203         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.625      0.486      0.493      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      2.32G     0.6941     0.4067     0.9257         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.705      0.415      0.491      0.354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      2.32G     0.6792     0.4026     0.9204         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:55<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.633      0.502      0.501      0.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      2.46G      0.633      0.355     0.8858         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.629       0.51      0.495       0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100       2.3G      0.612     0.3417     0.8797          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:53<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.815      0.523      0.575      0.393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      2.34G     0.5982     0.3338     0.8752         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:53<00:00,  2.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.685      0.492      0.508      0.383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      2.33G     0.5908      0.331     0.8703          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:52<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.789      0.526      0.561       0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      2.35G     0.5831     0.3303     0.8734         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:53<00:00,  2.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.788      0.478      0.566      0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      2.34G     0.5746     0.3239     0.8664          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.736      0.478      0.508      0.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      2.35G     0.5759      0.327     0.8665          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:56<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:05<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.716      0.524      0.558      0.373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      2.34G     0.5732     0.3224     0.8653          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:57<00:00,  2.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.721      0.525      0.546      0.378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100      2.34G     0.5559     0.3155     0.8629          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [01:00<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:04<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989       0.76      0.521      0.555       0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      2.34G      0.565     0.3181     0.8622          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:58<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:03<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.657      0.482      0.507      0.372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "100 epochs completed in 1.755 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.2 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.816      0.523      0.575      0.393\n",
            "                 chair        436         22      0.976      0.364      0.524      0.406\n",
            "               handbag        436         18      0.826      0.789      0.774      0.581\n",
            "                laptop        436          4      0.916       0.75      0.888      0.598\n",
            "                person        436        929      0.947      0.898      0.962      0.706\n",
            "          refrigerator        436          4      0.434      0.217      0.207      0.162\n",
            "            teddy bear        436          3      0.958      0.667      0.685      0.208\n",
            "                    tv        436          6      0.473        0.5       0.56      0.483\n",
            "                  vase        436          3          1          0          0          0\n",
            "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Ultralytics YOLOv8.2.2 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/person_camera_security1-20/valid/labels.cache... 436 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:08<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.815      0.523      0.575      0.392\n",
            "                 chair        436         22      0.974      0.364      0.527      0.408\n",
            "               handbag        436         18      0.826       0.79      0.774      0.583\n",
            "                laptop        436          4      0.913       0.75      0.888      0.598\n",
            "                person        436        929      0.946      0.897      0.962      0.706\n",
            "          refrigerator        436          4      0.434      0.217      0.207      0.148\n",
            "            teddy bear        436          3      0.957      0.667      0.685      0.208\n",
            "                    tv        436          6      0.473        0.5      0.561      0.483\n",
            "                  vase        436          3          1          0          0          0\n",
            "Speed: 0.2ms preprocess, 6.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 476k/476k [00:00<00:00, 12.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 1/1 /content/bus.jpg: 640x480 1 chair, 4 persons, 17.4ms\n",
            "Speed: 2.4ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.2 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.30GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (6.0 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.9/15.9 MB 93.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 10.0s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 10.9s, saved as 'runs/detect/train2/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (12.6s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train2/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train2/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train2/weights/best.onnx imgsz=640 data=/content/person_camera_security1-20/data.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ourmodel = model\n",
        "\n",
        "\n",
        "validate = ourmodel.val()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ol5nHDdLwTV",
        "outputId": "8f9b10e4-d325-4207-a348-b9f37148c597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.2 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/person_camera_security1-20/valid/labels.cache... 436 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436/436 [00:00<?, ?it/s]\n",
            "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:09<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        436        989      0.815      0.523      0.575      0.392\n",
            "                 chair        436         22      0.974      0.364      0.527      0.408\n",
            "               handbag        436         18      0.826       0.79      0.774      0.583\n",
            "                laptop        436          4      0.913       0.75      0.888      0.598\n",
            "                person        436        929      0.946      0.897      0.962      0.706\n",
            "          refrigerator        436          4      0.434      0.217      0.207      0.148\n",
            "            teddy bear        436          3      0.957      0.667      0.685      0.208\n",
            "                    tv        436          6      0.473        0.5      0.561      0.483\n",
            "                  vase        436          3          1          0          0          0\n",
            "Speed: 0.6ms preprocess, 4.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train23\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###as we can see above, our model is doing the best with the person on the validation data. This is indeed what we want."
      ],
      "metadata": {
        "id": "OcQfO3jXNPqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_model = YOLO(\"yolov8n.pt\")\n",
        "my_model = YOLO(\"best.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WRcIlaZ7jVsa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lzVRACnAnE0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultsmine= my_model.predict(\"/content/person_camera_security1-20/test/images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5vhksRcnFf5",
        "outputId": "dced1ab6-19b2-4caa-e6cd-4625ff8d4d7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/222 /content/person_camera_security1-20/test/images/000000009400_jpg.rf.6b24df2c7ea9237bef02155db66210be.jpg: 480x640 1 person, 559.0ms\n",
            "image 2/222 /content/person_camera_security1-20/test/images/000000017379_jpg.rf.da1abc9974f8577a50c3b2d6ff35a890.jpg: 640x480 1 tv, 173.9ms\n",
            "image 3/222 /content/person_camera_security1-20/test/images/000000031248_jpg.rf.f851bb802826329f891d38f439279b99.jpg: 448x640 1 person, 168.4ms\n",
            "image 4/222 /content/person_camera_security1-20/test/images/000000041872_jpg.rf.de3dd0e396b951017d0cf92859eee6c6.jpg: 448x640 (no detections), 163.7ms\n",
            "image 5/222 /content/person_camera_security1-20/test/images/000000046031_jpg.rf.f19c45d22cb429ae261af070413a3ece.jpg: 480x640 1 laptop, 174.9ms\n",
            "image 6/222 /content/person_camera_security1-20/test/images/000000057232_jpg.rf.eae866119ba8b0526b7d479ca62f8f7d.jpg: 640x640 (no detections), 226.2ms\n",
            "image 7/222 /content/person_camera_security1-20/test/images/000000063740_jpg.rf.978117b93dc39ce1e37daeeb256478b6.jpg: 480x640 1 laptop, 1 person, 2 tvs, 148.1ms\n",
            "image 8/222 /content/person_camera_security1-20/test/images/000000080057_jpg.rf.3ec381d08d05a1767aad2b18beb46d60.jpg: 640x448 2 teddy bears, 151.9ms\n",
            "image 9/222 /content/person_camera_security1-20/test/images/000000082696_jpg.rf.da7c2719c7a430f9700a1cb9f29878f1.jpg: 640x448 (no detections), 145.1ms\n",
            "image 10/222 /content/person_camera_security1-20/test/images/000000097022_jpg.rf.302450298fbf160c17bca4563b07c6c9.jpg: 448x640 1 chair, 1 microwave, 154.7ms\n",
            "image 11/222 /content/person_camera_security1-20/test/images/0c7e2ff6-4ef5-11eb-8169-fa1ce9dbafb6_jpg.rf.7ce7497d9fd60b46f731b311047ca777.jpg: 384x640 2 persons, 131.4ms\n",
            "image 12/222 /content/person_camera_security1-20/test/images/1012_person_jpg.rf.8d65c3347f1034835a05a3705e168e8b.jpg: 384x640 (no detections), 118.9ms\n",
            "image 13/222 /content/person_camera_security1-20/test/images/1013_person_jpg.rf.d622b72f43eb993ffffacc4bd80013e9.jpg: 384x640 (no detections), 137.0ms\n",
            "image 14/222 /content/person_camera_security1-20/test/images/1015_person_jpg.rf.b3144a00464b9ce55fd80516fe15db0f.jpg: 384x640 (no detections), 117.6ms\n",
            "image 15/222 /content/person_camera_security1-20/test/images/1022_person_jpg.rf.112002979b5bfb3aa5cfa098353061c1.jpg: 384x640 (no detections), 130.8ms\n",
            "image 16/222 /content/person_camera_security1-20/test/images/1031_person_jpg.rf.2561dccfad7fd80c78df0b3ceced8893.jpg: 384x640 1 person, 120.9ms\n",
            "image 17/222 /content/person_camera_security1-20/test/images/1037_person_jpg.rf.a6642ba15190874f88789c0316732e34.jpg: 384x640 1 person, 127.2ms\n",
            "image 18/222 /content/person_camera_security1-20/test/images/1039_person_jpg.rf.73b2854e7bd8effaa2d79f6d6e9dfcae.jpg: 384x640 1 person, 135.3ms\n",
            "image 19/222 /content/person_camera_security1-20/test/images/1074_person_jpg.rf.8b8e5c083de892e22e40bdb44ce098c0.jpg: 384x640 1 person, 122.4ms\n",
            "image 20/222 /content/person_camera_security1-20/test/images/1080_person_jpg.rf.8be1004792a513199f4548461d62fd83.jpg: 384x640 (no detections), 123.7ms\n",
            "image 21/222 /content/person_camera_security1-20/test/images/1082_person_jpg.rf.62c13275d809e05dc1c9aa1b032fb945.jpg: 384x640 (no detections), 121.4ms\n",
            "image 22/222 /content/person_camera_security1-20/test/images/1095_person_jpg.rf.0216abc9b7bace5c128852e831622598.jpg: 384x640 1 person, 120.0ms\n",
            "image 23/222 /content/person_camera_security1-20/test/images/1106_person_jpg.rf.379e6e9791fca750c67cfbb1e957d483.jpg: 384x640 1 person, 120.4ms\n",
            "image 24/222 /content/person_camera_security1-20/test/images/1113_person_jpg.rf.6468514e25e756aeb691548df58030a7.jpg: 384x640 1 person, 118.7ms\n",
            "image 25/222 /content/person_camera_security1-20/test/images/111_person_jpg.rf.e29b10a356f4e61e36cc449e7d722e79.jpg: 384x640 2 persons, 120.5ms\n",
            "image 26/222 /content/person_camera_security1-20/test/images/1125_person_jpg.rf.22506b2738c0d1172c72835457d66d93.jpg: 384x640 1 person, 131.2ms\n",
            "image 27/222 /content/person_camera_security1-20/test/images/1130_person_jpg.rf.6495608fecb9e35122b49049a0d37dc6.jpg: 384x640 1 person, 122.8ms\n",
            "image 28/222 /content/person_camera_security1-20/test/images/1145_person_jpg.rf.09ec81ca3b22126c07703b9b168f98d5.jpg: 384x640 1 person, 119.4ms\n",
            "image 29/222 /content/person_camera_security1-20/test/images/1146_person_jpg.rf.c8b4456f33e1d2f00f38dd5d0bc0439c.jpg: 384x640 1 person, 120.3ms\n",
            "image 30/222 /content/person_camera_security1-20/test/images/1148_person_jpg.rf.aeed3f2f7b88534332d0748fdd71db4b.jpg: 384x640 1 person, 119.4ms\n",
            "image 31/222 /content/person_camera_security1-20/test/images/1150_person_jpg.rf.3224c076487b4958a6a8c2118f00c6c5.jpg: 384x640 1 person, 123.9ms\n",
            "image 32/222 /content/person_camera_security1-20/test/images/1162_person_jpg.rf.666c53b886a95f38ec5fe096df5030b1.jpg: 384x640 1 person, 118.2ms\n",
            "image 33/222 /content/person_camera_security1-20/test/images/1178_person_jpg.rf.b37b0de78e780448da81f91624a4b622.jpg: 384x640 1 person, 116.9ms\n",
            "image 34/222 /content/person_camera_security1-20/test/images/1206_person_jpg.rf.5871aca6ca3cc3aee51d5d76dc393f86.jpg: 384x640 1 person, 128.2ms\n",
            "image 35/222 /content/person_camera_security1-20/test/images/1226_person_jpg.rf.04d30a2617945e603c962667c4e59942.jpg: 384x640 1 person, 118.0ms\n",
            "image 36/222 /content/person_camera_security1-20/test/images/1244_person_jpg.rf.77eb642cdeab1833114179de33d58e48.jpg: 384x640 1 person, 128.5ms\n",
            "image 37/222 /content/person_camera_security1-20/test/images/1268_person_jpg.rf.2b740c45cb9d95bc0cacd3cce4889205.jpg: 384x640 1 person, 125.8ms\n",
            "image 38/222 /content/person_camera_security1-20/test/images/1269_person_jpg.rf.d5d529429fbc5491d9d998e449f872b3.jpg: 384x640 1 person, 131.9ms\n",
            "image 39/222 /content/person_camera_security1-20/test/images/1282_person_jpg.rf.92b857bc90165640ec38af588c5a4847.jpg: 384x640 1 person, 152.1ms\n",
            "image 40/222 /content/person_camera_security1-20/test/images/1288_person_jpg.rf.85e00ac88cbd5ddae27f7ea83eda6b41.jpg: 384x640 1 person, 193.8ms\n",
            "image 41/222 /content/person_camera_security1-20/test/images/128_person_jpg.rf.a917e92e870b0d73418f68620e4ec294.jpg: 384x640 1 person, 190.0ms\n",
            "image 42/222 /content/person_camera_security1-20/test/images/1310_person_jpg.rf.f92e91c3dab20cfd859442be8bcf48c3.jpg: 384x640 1 person, 189.1ms\n",
            "image 43/222 /content/person_camera_security1-20/test/images/1322_person_jpg.rf.b024ed975dbc181584fd0e2ed07dd805.jpg: 384x640 1 person, 187.8ms\n",
            "image 44/222 /content/person_camera_security1-20/test/images/1334_person_jpg.rf.ecfbff4cc899c1ca888e290b6604d9d5.jpg: 384x640 1 person, 188.9ms\n",
            "image 45/222 /content/person_camera_security1-20/test/images/1376_person_jpg.rf.7b4f96993e1daa6453ec7243e391561c.jpg: 384x640 2 persons, 196.5ms\n",
            "image 46/222 /content/person_camera_security1-20/test/images/1399_person_jpg.rf.b3e3add8477b2fdf292ed090811c826d.jpg: 384x640 2 persons, 189.5ms\n",
            "image 47/222 /content/person_camera_security1-20/test/images/1401_person_jpg.rf.81bdf367601d4aec7b5cf7d5c9e88165.jpg: 384x640 2 persons, 201.1ms\n",
            "image 48/222 /content/person_camera_security1-20/test/images/1427_person_jpg.rf.660f0f289c9a08b2aaa72587ecf53e3a.jpg: 384x640 3 persons, 193.0ms\n",
            "image 49/222 /content/person_camera_security1-20/test/images/1439_person_jpg.rf.e638549913451be92afd932949aded79.jpg: 384x640 1 person, 198.0ms\n",
            "image 50/222 /content/person_camera_security1-20/test/images/1445_person_jpg.rf.d5bfe89f66872fc56178f9768d3a80f9.jpg: 384x640 3 persons, 182.8ms\n",
            "image 51/222 /content/person_camera_security1-20/test/images/144_person_jpg.rf.71f8fcb9c0fa9d6abb2c0ddb089e3985.jpg: 384x640 2 persons, 192.4ms\n",
            "image 52/222 /content/person_camera_security1-20/test/images/1451_person_jpg.rf.2e837b7257b2becb30ea2c370df06a99.jpg: 384x640 3 persons, 123.3ms\n",
            "image 53/222 /content/person_camera_security1-20/test/images/1454_person_jpg.rf.28beb5da9323defeff0c661e03f2385b.jpg: 384x640 3 persons, 124.4ms\n",
            "image 54/222 /content/person_camera_security1-20/test/images/1459_person_jpg.rf.d1d078eab0b95d0d8a22139527297f9f.jpg: 384x640 2 persons, 116.8ms\n",
            "image 55/222 /content/person_camera_security1-20/test/images/1466_person_jpg.rf.09c30bc494ec8f68aac59a355be09399.jpg: 384x640 3 persons, 120.2ms\n",
            "image 56/222 /content/person_camera_security1-20/test/images/1469_person_jpg.rf.a12eee85a70a75e8c6f3ae0d22740d6b.jpg: 384x640 2 persons, 127.2ms\n",
            "image 57/222 /content/person_camera_security1-20/test/images/147_person_jpg.rf.cfa4784c720ab44dfd4062fe4e3f2473.jpg: 384x640 2 persons, 198.8ms\n",
            "image 58/222 /content/person_camera_security1-20/test/images/1485_person_jpg.rf.75520171891f8e42053db5e23f7c45b6.jpg: 384x640 2 persons, 186.8ms\n",
            "image 59/222 /content/person_camera_security1-20/test/images/1495_person_jpg.rf.79dc689ffd3e8a9dc09272c87349c081.jpg: 384x640 2 persons, 188.3ms\n",
            "image 60/222 /content/person_camera_security1-20/test/images/1498_person_jpg.rf.5759d33af88a47f1875ea191d9b22be1.jpg: 384x640 2 persons, 192.7ms\n",
            "image 61/222 /content/person_camera_security1-20/test/images/1508_person_jpg.rf.8484a3283ecc67bb8bd128b448a897a2.jpg: 384x640 2 persons, 192.6ms\n",
            "image 62/222 /content/person_camera_security1-20/test/images/1523_person_jpg.rf.c4166630fda87c58ea5d452804c0f85a.jpg: 384x640 1 person, 181.3ms\n",
            "image 63/222 /content/person_camera_security1-20/test/images/1529_person_jpg.rf.7d7aff23cb1f7199c0c47d73e91dc50e.jpg: 384x640 1 person, 191.2ms\n",
            "image 64/222 /content/person_camera_security1-20/test/images/1544_person_jpg.rf.8a2121b3d9ab2fd237c6a4a9ff2bd902.jpg: 384x640 1 person, 200.1ms\n",
            "image 65/222 /content/person_camera_security1-20/test/images/1554_person_jpg.rf.53d4b6a08b5a1a6778122f0e8c499ad0.jpg: 384x640 2 persons, 189.2ms\n",
            "image 66/222 /content/person_camera_security1-20/test/images/1555_person_jpg.rf.dc51f90cdd339d9c6259982ffd91e4cc.jpg: 384x640 2 persons, 189.2ms\n",
            "image 67/222 /content/person_camera_security1-20/test/images/1571_person_jpg.rf.09372260d3276687fbb415613b78bbd3.jpg: 384x640 2 persons, 183.1ms\n",
            "image 68/222 /content/person_camera_security1-20/test/images/157_person_jpg.rf.30e44f3e83d07feac6a45d5d29156021.jpg: 384x640 2 persons, 193.4ms\n",
            "image 69/222 /content/person_camera_security1-20/test/images/1596_person_jpg.rf.a1771eb44fa0b3333caf338826deec19.jpg: 384x640 1 person, 127.0ms\n",
            "image 70/222 /content/person_camera_security1-20/test/images/1598_person_jpg.rf.b2428274e67f1a149d59ea072b1512bd.jpg: 384x640 1 person, 121.3ms\n",
            "image 71/222 /content/person_camera_security1-20/test/images/1603_person_jpg.rf.38ae05f216053d492c6b91a85c7ab8e6.jpg: 384x640 1 person, 118.2ms\n",
            "image 72/222 /content/person_camera_security1-20/test/images/1606_person_jpg.rf.cce0f2a33a35a49b0b28e8d9af271a11.jpg: 384x640 1 person, 116.4ms\n",
            "image 73/222 /content/person_camera_security1-20/test/images/1614_person_jpg.rf.26053f5d9522b8fd7763f5f7f12829fe.jpg: 384x640 1 person, 121.8ms\n",
            "image 74/222 /content/person_camera_security1-20/test/images/1619_person_jpg.rf.116d4d3a1312ba50f7447077c1d0815f.jpg: 384x640 1 person, 117.8ms\n",
            "image 75/222 /content/person_camera_security1-20/test/images/1625_person_jpg.rf.09ac1b42ebab9610b0b839b147693163.jpg: 384x640 1 person, 127.3ms\n",
            "image 76/222 /content/person_camera_security1-20/test/images/1631_person_jpg.rf.54333251fb6b9a7bf5f89fafaf58fd36.jpg: 384x640 1 person, 125.8ms\n",
            "image 77/222 /content/person_camera_security1-20/test/images/1634_person_jpg.rf.b1f57618b02c0b59d88d316eea2c9c20.jpg: 384x640 1 person, 121.9ms\n",
            "image 78/222 /content/person_camera_security1-20/test/images/1640_person_jpg.rf.8d74b786b9428c3646933b13c9d51c72.jpg: 384x640 1 person, 120.8ms\n",
            "image 79/222 /content/person_camera_security1-20/test/images/1641_person_jpg.rf.e6dcdbb8dc1cd39b9a2a4b2704e245eb.jpg: 384x640 1 person, 130.7ms\n",
            "image 80/222 /content/person_camera_security1-20/test/images/1643_person_jpg.rf.ba879745956523be938f432da24965a7.jpg: 384x640 1 person, 116.2ms\n",
            "image 81/222 /content/person_camera_security1-20/test/images/1655_person_jpg.rf.3b752ec5e330342084b866ee26eafa50.jpg: 384x640 1 person, 120.9ms\n",
            "image 82/222 /content/person_camera_security1-20/test/images/1674_person_jpg.rf.21523a0a0e6f7c8aad18686a16e95d76.jpg: 384x640 1 person, 128.6ms\n",
            "image 83/222 /content/person_camera_security1-20/test/images/1678_person_jpg.rf.fe172c60dc92c49685f5233482a327b1.jpg: 384x640 1 person, 129.5ms\n",
            "image 84/222 /content/person_camera_security1-20/test/images/1689_person_jpg.rf.b6da213032f6a77b454dbd2821994eeb.jpg: 384x640 1 person, 115.7ms\n",
            "image 85/222 /content/person_camera_security1-20/test/images/1707_person_jpg.rf.3a5cb5aa44f9e8ba6b9e22f7c74cfb41.jpg: 384x640 1 person, 119.3ms\n",
            "image 86/222 /content/person_camera_security1-20/test/images/1738_person_jpg.rf.098fceebda05a56c3b47be9f856bde6b.jpg: 384x640 1 person, 127.4ms\n",
            "image 87/222 /content/person_camera_security1-20/test/images/173_person_jpg.rf.66ae6b4f61f4b4c78720e9d99f7d2545.jpg: 384x640 1 person, 120.6ms\n",
            "image 88/222 /content/person_camera_security1-20/test/images/1745_person_jpg.rf.308e3c34ae1610c2b13aa1ebed4787dd.jpg: 384x640 1 person, 120.8ms\n",
            "image 89/222 /content/person_camera_security1-20/test/images/1774_person_jpg.rf.84dea4065a0c4adddd1d473881195653.jpg: 384x640 2 persons, 119.4ms\n",
            "image 90/222 /content/person_camera_security1-20/test/images/1776_person_jpg.rf.7a8a4468f8c344b18a19e7006e89d4ce.jpg: 384x640 2 persons, 123.8ms\n",
            "image 91/222 /content/person_camera_security1-20/test/images/1778_person_jpg.rf.af1a0096d7a7195041749a2ac2245711.jpg: 384x640 1 person, 135.8ms\n",
            "image 92/222 /content/person_camera_security1-20/test/images/1805_person_jpg.rf.d74d963586a9000754099457f0dc31ba.jpg: 384x640 1 person, 124.1ms\n",
            "image 93/222 /content/person_camera_security1-20/test/images/1811_person_jpg.rf.89c0276af0bca90c17bfcd1ebec40b48.jpg: 384x640 1 person, 131.5ms\n",
            "image 94/222 /content/person_camera_security1-20/test/images/1815_person_jpg.rf.d526f6aecec22b394840f66fee996bdc.jpg: 384x640 1 person, 116.1ms\n",
            "image 95/222 /content/person_camera_security1-20/test/images/1834_person_jpg.rf.a20486c9fa76c6099bb4fb599c189f37.jpg: 384x640 1 person, 118.9ms\n",
            "image 96/222 /content/person_camera_security1-20/test/images/1837_person_jpg.rf.303d1e626d881536469c4245ffa6146d.jpg: 384x640 1 person, 118.1ms\n",
            "image 97/222 /content/person_camera_security1-20/test/images/1840_person_jpg.rf.bf46e97a792495941a4f5b32a2658468.jpg: 384x640 1 person, 115.4ms\n",
            "image 98/222 /content/person_camera_security1-20/test/images/1843_person_jpg.rf.36c24b5b7d5306c9ee5c706c51267f52.jpg: 384x640 1 person, 123.4ms\n",
            "image 99/222 /content/person_camera_security1-20/test/images/1845_person_jpg.rf.bd0eff40d73fc055964dbb2dec44cb27.jpg: 384x640 1 person, 132.8ms\n",
            "image 100/222 /content/person_camera_security1-20/test/images/1851_person_jpg.rf.15e9b20753b1a15530334ddbedf14f83.jpg: 384x640 1 person, 127.2ms\n",
            "image 101/222 /content/person_camera_security1-20/test/images/1859_person_jpg.rf.8b6dd741bf8978d1df7b62df258cf5dd.jpg: 384x640 1 person, 128.2ms\n",
            "image 102/222 /content/person_camera_security1-20/test/images/186_person_jpg.rf.6cc1a578d0d7c606e2b1272153696b88.jpg: 384x640 1 person, 120.2ms\n",
            "image 103/222 /content/person_camera_security1-20/test/images/1880_person_jpg.rf.a0773128805f41fad6ca0f57a5d9e759.jpg: 384x640 3 persons, 121.3ms\n",
            "image 104/222 /content/person_camera_security1-20/test/images/1883_person_jpg.rf.44cae69d6471cf5edc757789a45b54ce.jpg: 384x640 3 persons, 116.7ms\n",
            "image 105/222 /content/person_camera_security1-20/test/images/1ecfe8e0-5c68-11eb-8b40-be7fb69f1d58_jpg.rf.5af4ee5e8326f541df52e2c7b0d85f6e.jpg: 384x640 1 person, 123.8ms\n",
            "image 106/222 /content/person_camera_security1-20/test/images/210_person_jpg.rf.237441df3dab09b09ff4e91395dcb5bf.jpg: 384x640 (no detections), 128.6ms\n",
            "image 107/222 /content/person_camera_security1-20/test/images/213_person_jpg.rf.1f4ea6fbbc79064cd9e04c26abc693c7.jpg: 384x640 2 persons, 117.9ms\n",
            "image 108/222 /content/person_camera_security1-20/test/images/215_person_jpg.rf.0fd501f61e546b509a8cace25c0ba9fb.jpg: 384x640 2 persons, 133.2ms\n",
            "image 109/222 /content/person_camera_security1-20/test/images/216_person_jpg.rf.3ce4913457304266deabb886ff65c874.jpg: 384x640 2 persons, 127.3ms\n",
            "image 110/222 /content/person_camera_security1-20/test/images/221_person_jpg.rf.79b25cc009a7b1bc3170cde16f1dc1ae.jpg: 384x640 1 person, 117.2ms\n",
            "image 111/222 /content/person_camera_security1-20/test/images/229_person_jpg.rf.5d6abc193938e8d721bc4b46d1e6eb19.jpg: 384x640 1 person, 174.8ms\n",
            "image 112/222 /content/person_camera_security1-20/test/images/284_person_jpg.rf.c109a609e84b29d9d675935210bd5f93.jpg: 384x640 1 person, 198.0ms\n",
            "image 113/222 /content/person_camera_security1-20/test/images/286_person_jpg.rf.6dec0214a88b1906a9ea5f6f9fb3ef3f.jpg: 384x640 1 person, 209.0ms\n",
            "image 114/222 /content/person_camera_security1-20/test/images/28_person_jpg.rf.5fd53416377e856ec17802aa23d9ba36.jpg: 384x640 1 person, 197.4ms\n",
            "image 115/222 /content/person_camera_security1-20/test/images/291_person_jpg.rf.e6c5e03f364accb612a9c4ea3e1e8ad4.jpg: 384x640 1 person, 157.8ms\n",
            "image 116/222 /content/person_camera_security1-20/test/images/293_person_jpg.rf.f2a18749e641333b89b22f3f12274ec1.jpg: 384x640 1 person, 114.8ms\n",
            "image 117/222 /content/person_camera_security1-20/test/images/322_person_jpg.rf.10018cc28a9b2ebc030c378288fff301.jpg: 384x640 1 person, 126.4ms\n",
            "image 118/222 /content/person_camera_security1-20/test/images/324_person_jpg.rf.8d99d67f5f212b6eb1412550a2138810.jpg: 384x640 1 person, 119.1ms\n",
            "image 119/222 /content/person_camera_security1-20/test/images/32_person_jpg.rf.562410eb2406a3c6cbb364200178f48e.jpg: 384x640 1 person, 140.7ms\n",
            "image 120/222 /content/person_camera_security1-20/test/images/330_person_jpg.rf.0519ac7254e104e381376a48cae7e9d5.jpg: 384x640 1 person, 124.6ms\n",
            "image 121/222 /content/person_camera_security1-20/test/images/337_person_jpg.rf.a6060f3eaa961cf3e2c1fb6279b59513.jpg: 384x640 1 person, 126.5ms\n",
            "image 122/222 /content/person_camera_security1-20/test/images/339_person_jpg.rf.7ccce6e17166c7872f91326e62f5957e.jpg: 384x640 1 person, 186.1ms\n",
            "image 123/222 /content/person_camera_security1-20/test/images/347_person_jpg.rf.458a9f657c54f22a46f57dc516fab9d9.jpg: 384x640 1 person, 183.7ms\n",
            "image 124/222 /content/person_camera_security1-20/test/images/351_person_jpg.rf.f1867f2572632eb5b6a1a0cdccd3df34.jpg: 384x640 1 person, 191.3ms\n",
            "image 125/222 /content/person_camera_security1-20/test/images/361_person_jpg.rf.7eadc6d2a53a6940cb616ecbcc88ab9d.jpg: 384x640 1 person, 185.1ms\n",
            "image 126/222 /content/person_camera_security1-20/test/images/38_person_jpg.rf.c78bc0f493be5adf99658a206c8abfd4.jpg: 384x640 1 person, 123.4ms\n",
            "image 127/222 /content/person_camera_security1-20/test/images/396_person_jpg.rf.23325c3e88ec1db78a59471134e67229.jpg: 384x640 1 person, 608.9ms\n",
            "image 128/222 /content/person_camera_security1-20/test/images/40_person_jpg.rf.7f780c94d09ff5618b2d42767fa580f7.jpg: 384x640 1 person, 614.6ms\n",
            "image 129/222 /content/person_camera_security1-20/test/images/421_person_jpg.rf.e65575b26b00e80b50037c612d92db28.jpg: 384x640 1 person, 395.9ms\n",
            "image 130/222 /content/person_camera_security1-20/test/images/428_person_jpg.rf.e5736b92e1f32efd85377282e06a010c.jpg: 384x640 1 person, 224.7ms\n",
            "image 131/222 /content/person_camera_security1-20/test/images/430_person_jpg.rf.fd81c9b272196d1ffa64dfb4a95145ec.jpg: 384x640 1 person, 184.7ms\n",
            "image 132/222 /content/person_camera_security1-20/test/images/43_person_jpg.rf.cbc606a948470d6936fa08b6d8330597.jpg: 384x640 1 person, 182.5ms\n",
            "image 133/222 /content/person_camera_security1-20/test/images/446_person_jpg.rf.e2e53299b2cb95290bf2f08610449f92.jpg: 384x640 1 person, 184.0ms\n",
            "image 134/222 /content/person_camera_security1-20/test/images/450_person_jpg.rf.764c45192f4f5d9cb5ee990bf29aebb2.jpg: 384x640 1 person, 186.5ms\n",
            "image 135/222 /content/person_camera_security1-20/test/images/456_person_jpg.rf.d0684bbc184d3161727a6b45bc050709.jpg: 384x640 1 person, 204.8ms\n",
            "image 136/222 /content/person_camera_security1-20/test/images/45_person_jpg.rf.4d91f0ed267585ba8635681b25cff3e4.jpg: 384x640 1 person, 185.4ms\n",
            "image 137/222 /content/person_camera_security1-20/test/images/460_person_jpg.rf.6665517fa0f120a4c14d6973b536356f.jpg: 384x640 1 person, 191.0ms\n",
            "image 138/222 /content/person_camera_security1-20/test/images/462_person_jpg.rf.281e6d0010aeaea93be68501e4c3355f.jpg: 384x640 1 person, 194.4ms\n",
            "image 139/222 /content/person_camera_security1-20/test/images/513_png_jpg.rf.220a9d3613ec4c31212e6cf55a75b9d1.jpg: 640x640 (no detections), 333.6ms\n",
            "image 140/222 /content/person_camera_security1-20/test/images/528_person_jpg.rf.623066f9dad9e25a8b2093a36a74d199.jpg: 384x640 1 person, 167.6ms\n",
            "image 141/222 /content/person_camera_security1-20/test/images/52_person_jpg.rf.d3317857888eff7c8485a19fb48a1d04.jpg: 384x640 1 person, 117.6ms\n",
            "image 142/222 /content/person_camera_security1-20/test/images/537_person_jpg.rf.9d40fa504ab401c045ba26a1410ee6c2.jpg: 384x640 2 persons, 119.3ms\n",
            "image 143/222 /content/person_camera_security1-20/test/images/568_person_jpg.rf.5d682d24d6f1ee9e89335eb780697066.jpg: 384x640 1 person, 116.3ms\n",
            "image 144/222 /content/person_camera_security1-20/test/images/58_person_jpg.rf.5aab23c8be9b54e970fbc39fff4eb7bb.jpg: 384x640 1 person, 124.5ms\n",
            "image 145/222 /content/person_camera_security1-20/test/images/594_person_jpg.rf.6ad8db0acdbc1aa9a7830f0fbec97a6a.jpg: 384x640 1 person, 125.2ms\n",
            "image 146/222 /content/person_camera_security1-20/test/images/595_person_jpg.rf.a9f3a73fbf8efd2cf8b39e8e7dfbb77f.jpg: 384x640 1 person, 123.7ms\n",
            "image 147/222 /content/person_camera_security1-20/test/images/59_person_jpg.rf.6046687b6c30813b158077ad08ec7a0c.jpg: 384x640 1 person, 134.5ms\n",
            "image 148/222 /content/person_camera_security1-20/test/images/5_person_jpg.rf.efee17b1c3a83a861fc4785fd46a35a2.jpg: 384x640 1 person, 125.6ms\n",
            "image 149/222 /content/person_camera_security1-20/test/images/612_person_jpg.rf.622cbdee895e4d2ba4636b68b8d1e8b3.jpg: 384x640 1 person, 119.2ms\n",
            "image 150/222 /content/person_camera_security1-20/test/images/613_person_jpg.rf.a4e2d084d6c83bac2d2421ad50b240f0.jpg: 384x640 1 person, 119.9ms\n",
            "image 151/222 /content/person_camera_security1-20/test/images/615_person_jpg.rf.fec090ac09f4a0a09a61cfe365232525.jpg: 384x640 1 person, 123.3ms\n",
            "image 152/222 /content/person_camera_security1-20/test/images/624_person_jpg.rf.4d1456db6835212361e1af0c0c32851f.jpg: 384x640 1 person, 120.9ms\n",
            "image 153/222 /content/person_camera_security1-20/test/images/625_person_jpg.rf.71ee2b2daf0c1be0cd7b4123f666bedc.jpg: 384x640 1 person, 123.0ms\n",
            "image 154/222 /content/person_camera_security1-20/test/images/643_person_jpg.rf.6e5228f136b8e9edbfcff9f2323a7e0e.jpg: 384x640 1 person, 135.3ms\n",
            "image 155/222 /content/person_camera_security1-20/test/images/648_person_jpg.rf.17d4a48641ee61e19d01ea39976a6481.jpg: 384x640 1 person, 127.6ms\n",
            "image 156/222 /content/person_camera_security1-20/test/images/65_person_jpg.rf.577a958905b753f3d9b9f96f6f49b82b.jpg: 384x640 1 person, 122.5ms\n",
            "image 157/222 /content/person_camera_security1-20/test/images/665_person_jpg.rf.b32f94b3fd179003906e147a3cf502c4.jpg: 384x640 1 person, 117.3ms\n",
            "image 158/222 /content/person_camera_security1-20/test/images/684_person_jpg.rf.9cd5d1cad4ec2a68ccacce95f6af48d3.jpg: 384x640 1 person, 127.1ms\n",
            "image 159/222 /content/person_camera_security1-20/test/images/6_person_jpg.rf.b471a2b81769c7c083a56e8ebdbd7dc3.jpg: 384x640 1 person, 119.7ms\n",
            "image 160/222 /content/person_camera_security1-20/test/images/700_person_jpg.rf.d24a5cc95762b5085dd14c4c07e33a89.jpg: 384x640 1 person, 122.0ms\n",
            "image 161/222 /content/person_camera_security1-20/test/images/706_person_jpg.rf.a3a6992018293df082f8bdc9e7da5ff9.jpg: 384x640 1 person, 131.4ms\n",
            "image 162/222 /content/person_camera_security1-20/test/images/722_person_jpg.rf.45c6d626eb90f13068ffdc39392ba1ae.jpg: 384x640 1 person, 127.8ms\n",
            "image 163/222 /content/person_camera_security1-20/test/images/732_person_jpg.rf.eafb63a22f442ea79e4742b39333be6d.jpg: 384x640 1 person, 118.8ms\n",
            "image 164/222 /content/person_camera_security1-20/test/images/741_person_jpg.rf.1835ed07be4543870f3153068e6c0d00.jpg: 384x640 3 persons, 117.0ms\n",
            "image 165/222 /content/person_camera_security1-20/test/images/743_person_jpg.rf.2efbec5cc6dd9edc2a536dbb940d53f8.jpg: 384x640 3 persons, 115.1ms\n",
            "image 166/222 /content/person_camera_security1-20/test/images/745_person_jpg.rf.1d6f00e7ab5dc62516fb0375c422ff39.jpg: 384x640 3 persons, 118.3ms\n",
            "image 167/222 /content/person_camera_security1-20/test/images/74_person_jpg.rf.7b147fce9fff8b79acb6f01a6db4873d.jpg: 384x640 1 person, 121.2ms\n",
            "image 168/222 /content/person_camera_security1-20/test/images/755_person_jpg.rf.4eb90f2938fa67990f882a0c5043dec4.jpg: 384x640 2 persons, 125.7ms\n",
            "image 169/222 /content/person_camera_security1-20/test/images/788_person_jpg.rf.7d4401868132780aabe71cdb8e0824ee.jpg: 384x640 1 person, 130.9ms\n",
            "image 170/222 /content/person_camera_security1-20/test/images/793_person_jpg.rf.6d2155285ea9872e4b96ef7f76ba4517.jpg: 384x640 1 person, 137.1ms\n",
            "image 171/222 /content/person_camera_security1-20/test/images/796_person_jpg.rf.3e8e256f02421dde8edcb4aa55efe6d8.jpg: 384x640 1 person, 125.6ms\n",
            "image 172/222 /content/person_camera_security1-20/test/images/798_person_jpg.rf.eb37c5d026906de307755ec2d59626a0.jpg: 384x640 1 person, 118.2ms\n",
            "image 173/222 /content/person_camera_security1-20/test/images/800_person_jpg.rf.bcd7c5e3b0160d92113e71834261a84a.jpg: 384x640 1 person, 117.6ms\n",
            "image 174/222 /content/person_camera_security1-20/test/images/95_person_jpg.rf.d54b2cc29b50322ac1f100925219f6ce.jpg: 384x640 2 persons, 118.5ms\n",
            "image 175/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_38-1-_mp4-75_jpg.rf.e48c3507c5a0fc56ba9fac02106469ae.jpg: 352x640 6 persons, 114.8ms\n",
            "image 176/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_39-1-_mp4-51_jpg.rf.c9c354fc693a5a391f32e668ec858092.jpg: 352x640 9 persons, 113.7ms\n",
            "image 177/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_39-1-_mp4-72_jpg.rf.39eba7b7db33bccced9cd55fdd2e578a.jpg: 352x640 5 persons, 111.5ms\n",
            "image 178/222 /content/person_camera_security1-20/test/images/crop_1420_jpg.rf.0bdf2ef5bd7ef3c1bb58f21002b53f48.jpg: 640x640 8 persons, 204.7ms\n",
            "image 179/222 /content/person_camera_security1-20/test/images/crop_2394_jpg.rf.28443e1ef476c4133c8eca021cf0831a.jpg: 640x640 7 persons, 196.0ms\n",
            "image 180/222 /content/person_camera_security1-20/test/images/crop_242_jpg.rf.a8a30fa9f7846e04d39c8e432115fe43.jpg: 640x640 9 persons, 197.4ms\n",
            "image 181/222 /content/person_camera_security1-20/test/images/crop_4039_jpg.rf.7af4f2bd80021242d162f036c1a01ed1.jpg: 640x640 4 persons, 185.3ms\n",
            "image 182/222 /content/person_camera_security1-20/test/images/crop_4137_jpg.rf.5ad2d80b2c79aa3d52573086d93cda2a.jpg: 640x640 3 persons, 218.7ms\n",
            "image 183/222 /content/person_camera_security1-20/test/images/oz_frame557_jpg.rf.9fa3b1db4225e6fd3951458ba88f4065.jpg: 384x640 2 persons, 115.9ms\n",
            "image 184/222 /content/person_camera_security1-20/test/images/person_100_jpg.rf.07f804bebbbec9448413ed52a4222277.jpg: 384x640 1 handbag, 13 persons, 115.7ms\n",
            "image 185/222 /content/person_camera_security1-20/test/images/person_112_jpg.rf.d8797604dcfcbefeca2a3175ee22fe47.jpg: 384x640 11 persons, 116.2ms\n",
            "image 186/222 /content/person_camera_security1-20/test/images/person_124_jpg.rf.332ec575863a56062d7183cc80d1697c.jpg: 384x640 11 persons, 127.3ms\n",
            "image 187/222 /content/person_camera_security1-20/test/images/person_13_jpg.rf.442a83621cd600428a7312b10110119d.jpg: 384x640 16 persons, 119.9ms\n",
            "image 188/222 /content/person_camera_security1-20/test/images/person_21_jpg.rf.3960312b631c2268f9500eadf91fc516.jpg: 384x640 1 handbag, 16 persons, 219.8ms\n",
            "image 189/222 /content/person_camera_security1-20/test/images/person_53_jpg.rf.704a1bda3ce3c415e18237f26c67194e.jpg: 384x640 1 handbag, 12 persons, 234.4ms\n",
            "image 190/222 /content/person_camera_security1-20/test/images/person_62_jpg.rf.0abef9e66df5902c35ca9eee58d4d146.jpg: 384x640 2 handbags, 13 persons, 224.2ms\n",
            "image 191/222 /content/person_camera_security1-20/test/images/person_63_jpg.rf.0e5314e067f3a45e78b73027ffe90727.jpg: 384x640 2 handbags, 12 persons, 124.5ms\n",
            "image 192/222 /content/person_camera_security1-20/test/images/person_64_jpg.rf.0cc55810301e50e200f4c192e3474a9b.jpg: 384x640 1 handbag, 13 persons, 158.3ms\n",
            "image 193/222 /content/person_camera_security1-20/test/images/person_79_jpg.rf.0e49a1064cf0360fb62019c50bb5d7dd.jpg: 384x640 2 handbags, 14 persons, 425.8ms\n",
            "image 194/222 /content/person_camera_security1-20/test/images/person_85_jpg.rf.2cfa372a981d478b66d11e4f6462a66a.jpg: 384x640 2 handbags, 15 persons, 480.6ms\n",
            "image 195/222 /content/person_camera_security1-20/test/images/person_89_jpg.rf.33f7e903771a44538f0849846cf286bf.jpg: 384x640 3 handbags, 12 persons, 257.0ms\n",
            "image 196/222 /content/person_camera_security1-20/test/images/point01_39_png_jpg.rf.0b8ccd0da46fe7029e5e62fdd34d5b9e.jpg: 384x640 4 persons, 282.6ms\n",
            "image 197/222 /content/person_camera_security1-20/test/images/point01_441_png_jpg.rf.29b3994e3e39c4cfefec78da828c2730.jpg: 384x640 2 persons, 283.9ms\n",
            "image 198/222 /content/person_camera_security1-20/test/images/point01_679_png_jpg.rf.a950046ad35ccea107c4fbf36a4b7a37.jpg: 384x640 2 persons, 180.5ms\n",
            "image 199/222 /content/person_camera_security1-20/test/images/point02_223_png_jpg.rf.c5bfd9a0d91214be91097cb80b875db1.jpg: 384x640 3 persons, 407.6ms\n",
            "image 200/222 /content/person_camera_security1-20/test/images/point02_438_png_jpg.rf.2a8477e3534dffd2017729c85b5ac9c3.jpg: 384x640 2 persons, 225.2ms\n",
            "image 201/222 /content/person_camera_security1-20/test/images/point02_93_png_jpg.rf.d0a80566cb306cdd1b84978fe6e97136.jpg: 384x640 1 person, 208.0ms\n",
            "image 202/222 /content/person_camera_security1-20/test/images/point03_113_png_jpg.rf.d5a0b6065ce1bab7dadd675a3760def2.jpg: 384x640 1 person, 297.8ms\n",
            "image 203/222 /content/person_camera_security1-20/test/images/point03_33_png_jpg.rf.0f99f5210b09aad4fefbcd8c9f5ac894.jpg: 384x640 1 person, 244.9ms\n",
            "image 204/222 /content/person_camera_security1-20/test/images/point03_51_png_jpg.rf.d076ec29dd130505be8446b86cf6eccc.jpg: 384x640 2 persons, 186.0ms\n",
            "image 205/222 /content/person_camera_security1-20/test/images/point03_65_png_jpg.rf.cac6fb2629262f3ab912c27ddadd8eb6.jpg: 384x640 1 person, 429.8ms\n",
            "image 206/222 /content/person_camera_security1-20/test/images/point03_95_png_jpg.rf.b5b7d70a2d781118781709903c621eab.jpg: 384x640 1 person, 240.1ms\n",
            "image 207/222 /content/person_camera_security1-20/test/images/point04_185_png_jpg.rf.23ef4b46adc7e00494040d26b4e20cf9.jpg: 384x640 2 persons, 419.2ms\n",
            "image 208/222 /content/person_camera_security1-20/test/images/point04_215_png_jpg.rf.6c37c73bad8674f20f266556fba8084d.jpg: 384x640 1 person, 277.5ms\n",
            "image 209/222 /content/person_camera_security1-20/test/images/point04_254_png_jpg.rf.8e51494dbd94b28bdb76826f193d1283.jpg: 384x640 1 person, 217.8ms\n",
            "image 210/222 /content/person_camera_security1-20/test/images/point04_275_png_jpg.rf.781e7b0752fad974b7be44f7d339f9c7.jpg: 384x640 2 persons, 273.3ms\n",
            "image 211/222 /content/person_camera_security1-20/test/images/point04_294_png_jpg.rf.c3ce6ffe45bfcfefd94f8bd44c3516c7.jpg: 384x640 2 persons, 213.1ms\n",
            "image 212/222 /content/person_camera_security1-20/test/images/point04_326_png_jpg.rf.5f38a472e4338f74f383cfb4f8cff08e.jpg: 384x640 1 person, 296.2ms\n",
            "image 213/222 /content/person_camera_security1-20/test/images/point04_354_png_jpg.rf.0303ba3f983db1c6b4801763a5e7c367.jpg: 384x640 2 persons, 486.1ms\n",
            "image 214/222 /content/person_camera_security1-20/test/images/point04_573_png_jpg.rf.f62780af0eb9d3e032a169a1538ac34a.jpg: 384x640 2 persons, 134.7ms\n",
            "image 215/222 /content/person_camera_security1-20/test/images/point05_166_png_jpg.rf.2cfd7ae224a7d02ed9821176896cb7f7.jpg: 384x640 1 person, 121.0ms\n",
            "image 216/222 /content/person_camera_security1-20/test/images/point05_201_png_jpg.rf.abc663b3c368225bd89d5463c665e193.jpg: 384x640 1 person, 271.6ms\n",
            "image 217/222 /content/person_camera_security1-20/test/images/point05_3_png_jpg.rf.98c608c3a9257150c9d689fd29372021.jpg: 384x640 2 persons, 208.6ms\n",
            "image 218/222 /content/person_camera_security1-20/test/images/point05_57_png_jpg.rf.16fa9cbc75d1513b02921ec0449d6c48.jpg: 384x640 (no detections), 323.8ms\n",
            "image 219/222 /content/person_camera_security1-20/test/images/point06_221_png_jpg.rf.4349c58dadc88d6228203ebffdc8cab1.jpg: 384x640 1 person, 123.4ms\n",
            "image 220/222 /content/person_camera_security1-20/test/images/point06_23_png_jpg.rf.e77b42475e34d0c4063d6d4b6a5de15b.jpg: 384x640 1 person, 143.7ms\n",
            "image 221/222 /content/person_camera_security1-20/test/images/point06_302_png_jpg.rf.bb0defeb14cb58f465e1f108c03f4f58.jpg: 384x640 1 person, 207.5ms\n",
            "image 222/222 /content/person_camera_security1-20/test/images/point06_69_png_jpg.rf.3c2da00c11bf29e4bd7e467c13791b3a.jpg: 384x640 1 person, 233.3ms\n",
            "Speed: 2.2ms preprocess, 169.7ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsdefault=  default_model.predict(\"/content/person_camera_security1-20/test/images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CsF6UQ5pjGt",
        "outputId": "df7ecd13-cc18-43dc-f31e-ce6a3458a0d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/222 /content/person_camera_security1-20/test/images/000000009400_jpg.rf.6b24df2c7ea9237bef02155db66210be.jpg: 480x640 9 persons, 4 cups, 6 laptops, 1 mouse, 1 keyboard, 189.1ms\n",
            "image 2/222 /content/person_camera_security1-20/test/images/000000017379_jpg.rf.da1abc9974f8577a50c3b2d6ff35a890.jpg: 640x480 1 tv, 2 sinks, 167.8ms\n",
            "image 3/222 /content/person_camera_security1-20/test/images/000000031248_jpg.rf.f851bb802826329f891d38f439279b99.jpg: 448x640 2 chairs, 1 couch, 2 potted plants, 2 books, 147.9ms\n",
            "image 4/222 /content/person_camera_security1-20/test/images/000000041872_jpg.rf.de3dd0e396b951017d0cf92859eee6c6.jpg: 448x640 2 chairs, 1 couch, 1 bed, 1 tv, 1 clock, 147.4ms\n",
            "image 5/222 /content/person_camera_security1-20/test/images/000000046031_jpg.rf.f19c45d22cb429ae261af070413a3ece.jpg: 480x640 1 tv, 1 laptop, 2 mouses, 1 keyboard, 2 cell phones, 165.4ms\n",
            "image 6/222 /content/person_camera_security1-20/test/images/000000057232_jpg.rf.eae866119ba8b0526b7d479ca62f8f7d.jpg: 640x640 1 vase, 218.4ms\n",
            "image 7/222 /content/person_camera_security1-20/test/images/000000063740_jpg.rf.978117b93dc39ce1e37daeeb256478b6.jpg: 480x640 5 persons, 1 bottle, 2 cups, 1 tv, 1 laptop, 2 keyboards, 1 cell phone, 155.5ms\n",
            "image 8/222 /content/person_camera_security1-20/test/images/000000080057_jpg.rf.3ec381d08d05a1767aad2b18beb46d60.jpg: 640x448 1 teddy bear, 158.6ms\n",
            "image 9/222 /content/person_camera_security1-20/test/images/000000082696_jpg.rf.da7c2719c7a430f9700a1cb9f29878f1.jpg: 640x448 1 bird, 3 chairs, 163.8ms\n",
            "image 10/222 /content/person_camera_security1-20/test/images/000000097022_jpg.rf.302450298fbf160c17bca4563b07c6c9.jpg: 448x640 1 bottle, 1 chair, 1 microwave, 2 ovens, 1 sink, 157.8ms\n",
            "image 11/222 /content/person_camera_security1-20/test/images/0c7e2ff6-4ef5-11eb-8169-fa1ce9dbafb6_jpg.rf.7ce7497d9fd60b46f731b311047ca777.jpg: 384x640 2 persons, 130.0ms\n",
            "image 12/222 /content/person_camera_security1-20/test/images/1012_person_jpg.rf.8d65c3347f1034835a05a3705e168e8b.jpg: 384x640 (no detections), 127.8ms\n",
            "image 13/222 /content/person_camera_security1-20/test/images/1013_person_jpg.rf.d622b72f43eb993ffffacc4bd80013e9.jpg: 384x640 (no detections), 126.7ms\n",
            "image 14/222 /content/person_camera_security1-20/test/images/1015_person_jpg.rf.b3144a00464b9ce55fd80516fe15db0f.jpg: 384x640 (no detections), 124.8ms\n",
            "image 15/222 /content/person_camera_security1-20/test/images/1022_person_jpg.rf.112002979b5bfb3aa5cfa098353061c1.jpg: 384x640 (no detections), 124.6ms\n",
            "image 16/222 /content/person_camera_security1-20/test/images/1031_person_jpg.rf.2561dccfad7fd80c78df0b3ceced8893.jpg: 384x640 (no detections), 127.8ms\n",
            "image 17/222 /content/person_camera_security1-20/test/images/1037_person_jpg.rf.a6642ba15190874f88789c0316732e34.jpg: 384x640 (no detections), 145.5ms\n",
            "image 18/222 /content/person_camera_security1-20/test/images/1039_person_jpg.rf.73b2854e7bd8effaa2d79f6d6e9dfcae.jpg: 384x640 (no detections), 135.3ms\n",
            "image 19/222 /content/person_camera_security1-20/test/images/1074_person_jpg.rf.8b8e5c083de892e22e40bdb44ce098c0.jpg: 384x640 (no detections), 127.2ms\n",
            "image 20/222 /content/person_camera_security1-20/test/images/1080_person_jpg.rf.8be1004792a513199f4548461d62fd83.jpg: 384x640 (no detections), 133.5ms\n",
            "image 21/222 /content/person_camera_security1-20/test/images/1082_person_jpg.rf.62c13275d809e05dc1c9aa1b032fb945.jpg: 384x640 (no detections), 135.9ms\n",
            "image 22/222 /content/person_camera_security1-20/test/images/1095_person_jpg.rf.0216abc9b7bace5c128852e831622598.jpg: 384x640 (no detections), 128.8ms\n",
            "image 23/222 /content/person_camera_security1-20/test/images/1106_person_jpg.rf.379e6e9791fca750c67cfbb1e957d483.jpg: 384x640 (no detections), 133.0ms\n",
            "image 24/222 /content/person_camera_security1-20/test/images/1113_person_jpg.rf.6468514e25e756aeb691548df58030a7.jpg: 384x640 (no detections), 145.9ms\n",
            "image 25/222 /content/person_camera_security1-20/test/images/111_person_jpg.rf.e29b10a356f4e61e36cc449e7d722e79.jpg: 384x640 1 person, 131.6ms\n",
            "image 26/222 /content/person_camera_security1-20/test/images/1125_person_jpg.rf.22506b2738c0d1172c72835457d66d93.jpg: 384x640 (no detections), 129.7ms\n",
            "image 27/222 /content/person_camera_security1-20/test/images/1130_person_jpg.rf.6495608fecb9e35122b49049a0d37dc6.jpg: 384x640 (no detections), 131.9ms\n",
            "image 28/222 /content/person_camera_security1-20/test/images/1145_person_jpg.rf.09ec81ca3b22126c07703b9b168f98d5.jpg: 384x640 (no detections), 126.9ms\n",
            "image 29/222 /content/person_camera_security1-20/test/images/1146_person_jpg.rf.c8b4456f33e1d2f00f38dd5d0bc0439c.jpg: 384x640 (no detections), 128.7ms\n",
            "image 30/222 /content/person_camera_security1-20/test/images/1148_person_jpg.rf.aeed3f2f7b88534332d0748fdd71db4b.jpg: 384x640 (no detections), 134.0ms\n",
            "image 31/222 /content/person_camera_security1-20/test/images/1150_person_jpg.rf.3224c076487b4958a6a8c2118f00c6c5.jpg: 384x640 (no detections), 130.3ms\n",
            "image 32/222 /content/person_camera_security1-20/test/images/1162_person_jpg.rf.666c53b886a95f38ec5fe096df5030b1.jpg: 384x640 1 person, 142.6ms\n",
            "image 33/222 /content/person_camera_security1-20/test/images/1178_person_jpg.rf.b37b0de78e780448da81f91624a4b622.jpg: 384x640 (no detections), 133.8ms\n",
            "image 34/222 /content/person_camera_security1-20/test/images/1206_person_jpg.rf.5871aca6ca3cc3aee51d5d76dc393f86.jpg: 384x640 (no detections), 134.1ms\n",
            "image 35/222 /content/person_camera_security1-20/test/images/1226_person_jpg.rf.04d30a2617945e603c962667c4e59942.jpg: 384x640 (no detections), 127.3ms\n",
            "image 36/222 /content/person_camera_security1-20/test/images/1244_person_jpg.rf.77eb642cdeab1833114179de33d58e48.jpg: 384x640 (no detections), 128.4ms\n",
            "image 37/222 /content/person_camera_security1-20/test/images/1268_person_jpg.rf.2b740c45cb9d95bc0cacd3cce4889205.jpg: 384x640 (no detections), 130.2ms\n",
            "image 38/222 /content/person_camera_security1-20/test/images/1269_person_jpg.rf.d5d529429fbc5491d9d998e449f872b3.jpg: 384x640 (no detections), 131.6ms\n",
            "image 39/222 /content/person_camera_security1-20/test/images/1282_person_jpg.rf.92b857bc90165640ec38af588c5a4847.jpg: 384x640 (no detections), 137.0ms\n",
            "image 40/222 /content/person_camera_security1-20/test/images/1288_person_jpg.rf.85e00ac88cbd5ddae27f7ea83eda6b41.jpg: 384x640 (no detections), 126.4ms\n",
            "image 41/222 /content/person_camera_security1-20/test/images/128_person_jpg.rf.a917e92e870b0d73418f68620e4ec294.jpg: 384x640 1 person, 163.7ms\n",
            "image 42/222 /content/person_camera_security1-20/test/images/1310_person_jpg.rf.f92e91c3dab20cfd859442be8bcf48c3.jpg: 384x640 1 person, 204.3ms\n",
            "image 43/222 /content/person_camera_security1-20/test/images/1322_person_jpg.rf.b024ed975dbc181584fd0e2ed07dd805.jpg: 384x640 1 person, 196.8ms\n",
            "image 44/222 /content/person_camera_security1-20/test/images/1334_person_jpg.rf.ecfbff4cc899c1ca888e290b6604d9d5.jpg: 384x640 1 bowl, 202.5ms\n",
            "image 45/222 /content/person_camera_security1-20/test/images/1376_person_jpg.rf.7b4f96993e1daa6453ec7243e391561c.jpg: 384x640 1 person, 1 tv, 190.7ms\n",
            "image 46/222 /content/person_camera_security1-20/test/images/1399_person_jpg.rf.b3e3add8477b2fdf292ed090811c826d.jpg: 384x640 2 persons, 190.5ms\n",
            "image 47/222 /content/person_camera_security1-20/test/images/1401_person_jpg.rf.81bdf367601d4aec7b5cf7d5c9e88165.jpg: 384x640 2 persons, 1 bottle, 195.3ms\n",
            "image 48/222 /content/person_camera_security1-20/test/images/1427_person_jpg.rf.660f0f289c9a08b2aaa72587ecf53e3a.jpg: 384x640 3 persons, 199.8ms\n",
            "image 49/222 /content/person_camera_security1-20/test/images/1439_person_jpg.rf.e638549913451be92afd932949aded79.jpg: 384x640 2 persons, 1 chair, 203.3ms\n",
            "image 50/222 /content/person_camera_security1-20/test/images/1445_person_jpg.rf.d5bfe89f66872fc56178f9768d3a80f9.jpg: 384x640 5 persons, 1 backpack, 209.0ms\n",
            "image 51/222 /content/person_camera_security1-20/test/images/144_person_jpg.rf.71f8fcb9c0fa9d6abb2c0ddb089e3985.jpg: 384x640 2 persons, 215.3ms\n",
            "image 52/222 /content/person_camera_security1-20/test/images/1451_person_jpg.rf.2e837b7257b2becb30ea2c370df06a99.jpg: 384x640 5 persons, 194.8ms\n",
            "image 53/222 /content/person_camera_security1-20/test/images/1454_person_jpg.rf.28beb5da9323defeff0c661e03f2385b.jpg: 384x640 2 persons, 130.1ms\n",
            "image 54/222 /content/person_camera_security1-20/test/images/1459_person_jpg.rf.d1d078eab0b95d0d8a22139527297f9f.jpg: 384x640 1 person, 1 skateboard, 130.5ms\n",
            "image 55/222 /content/person_camera_security1-20/test/images/1466_person_jpg.rf.09c30bc494ec8f68aac59a355be09399.jpg: 384x640 (no detections), 142.1ms\n",
            "image 56/222 /content/person_camera_security1-20/test/images/1469_person_jpg.rf.a12eee85a70a75e8c6f3ae0d22740d6b.jpg: 384x640 1 person, 126.9ms\n",
            "image 57/222 /content/person_camera_security1-20/test/images/147_person_jpg.rf.cfa4784c720ab44dfd4062fe4e3f2473.jpg: 384x640 2 persons, 135.8ms\n",
            "image 58/222 /content/person_camera_security1-20/test/images/1485_person_jpg.rf.75520171891f8e42053db5e23f7c45b6.jpg: 384x640 2 persons, 125.3ms\n",
            "image 59/222 /content/person_camera_security1-20/test/images/1495_person_jpg.rf.79dc689ffd3e8a9dc09272c87349c081.jpg: 384x640 1 person, 132.2ms\n",
            "image 60/222 /content/person_camera_security1-20/test/images/1498_person_jpg.rf.5759d33af88a47f1875ea191d9b22be1.jpg: 384x640 2 persons, 129.7ms\n",
            "image 61/222 /content/person_camera_security1-20/test/images/1508_person_jpg.rf.8484a3283ecc67bb8bd128b448a897a2.jpg: 384x640 1 person, 127.8ms\n",
            "image 62/222 /content/person_camera_security1-20/test/images/1523_person_jpg.rf.c4166630fda87c58ea5d452804c0f85a.jpg: 384x640 1 person, 143.3ms\n",
            "image 63/222 /content/person_camera_security1-20/test/images/1529_person_jpg.rf.7d7aff23cb1f7199c0c47d73e91dc50e.jpg: 384x640 1 person, 125.0ms\n",
            "image 64/222 /content/person_camera_security1-20/test/images/1544_person_jpg.rf.8a2121b3d9ab2fd237c6a4a9ff2bd902.jpg: 384x640 1 chair, 129.2ms\n",
            "image 65/222 /content/person_camera_security1-20/test/images/1554_person_jpg.rf.53d4b6a08b5a1a6778122f0e8c499ad0.jpg: 384x640 2 persons, 123.4ms\n",
            "image 66/222 /content/person_camera_security1-20/test/images/1555_person_jpg.rf.dc51f90cdd339d9c6259982ffd91e4cc.jpg: 384x640 2 persons, 133.8ms\n",
            "image 67/222 /content/person_camera_security1-20/test/images/1571_person_jpg.rf.09372260d3276687fbb415613b78bbd3.jpg: 384x640 2 persons, 1 bowl, 124.5ms\n",
            "image 68/222 /content/person_camera_security1-20/test/images/157_person_jpg.rf.30e44f3e83d07feac6a45d5d29156021.jpg: 384x640 3 persons, 129.1ms\n",
            "image 69/222 /content/person_camera_security1-20/test/images/1596_person_jpg.rf.a1771eb44fa0b3333caf338826deec19.jpg: 384x640 1 person, 124.9ms\n",
            "image 70/222 /content/person_camera_security1-20/test/images/1598_person_jpg.rf.b2428274e67f1a149d59ea072b1512bd.jpg: 384x640 1 person, 136.9ms\n",
            "image 71/222 /content/person_camera_security1-20/test/images/1603_person_jpg.rf.38ae05f216053d492c6b91a85c7ab8e6.jpg: 384x640 1 person, 125.5ms\n",
            "image 72/222 /content/person_camera_security1-20/test/images/1606_person_jpg.rf.cce0f2a33a35a49b0b28e8d9af271a11.jpg: 384x640 1 person, 123.1ms\n",
            "image 73/222 /content/person_camera_security1-20/test/images/1614_person_jpg.rf.26053f5d9522b8fd7763f5f7f12829fe.jpg: 384x640 1 person, 129.8ms\n",
            "image 74/222 /content/person_camera_security1-20/test/images/1619_person_jpg.rf.116d4d3a1312ba50f7447077c1d0815f.jpg: 384x640 1 person, 130.9ms\n",
            "image 75/222 /content/person_camera_security1-20/test/images/1625_person_jpg.rf.09ac1b42ebab9610b0b839b147693163.jpg: 384x640 1 person, 131.9ms\n",
            "image 76/222 /content/person_camera_security1-20/test/images/1631_person_jpg.rf.54333251fb6b9a7bf5f89fafaf58fd36.jpg: 384x640 (no detections), 125.0ms\n",
            "image 77/222 /content/person_camera_security1-20/test/images/1634_person_jpg.rf.b1f57618b02c0b59d88d316eea2c9c20.jpg: 384x640 (no detections), 137.5ms\n",
            "image 78/222 /content/person_camera_security1-20/test/images/1640_person_jpg.rf.8d74b786b9428c3646933b13c9d51c72.jpg: 384x640 1 person, 1 potted plant, 125.2ms\n",
            "image 79/222 /content/person_camera_security1-20/test/images/1641_person_jpg.rf.e6dcdbb8dc1cd39b9a2a4b2704e245eb.jpg: 384x640 1 potted plant, 127.2ms\n",
            "image 80/222 /content/person_camera_security1-20/test/images/1643_person_jpg.rf.ba879745956523be938f432da24965a7.jpg: 384x640 1 potted plant, 130.9ms\n",
            "image 81/222 /content/person_camera_security1-20/test/images/1655_person_jpg.rf.3b752ec5e330342084b866ee26eafa50.jpg: 384x640 1 person, 125.5ms\n",
            "image 82/222 /content/person_camera_security1-20/test/images/1674_person_jpg.rf.21523a0a0e6f7c8aad18686a16e95d76.jpg: 384x640 1 person, 128.5ms\n",
            "image 83/222 /content/person_camera_security1-20/test/images/1678_person_jpg.rf.fe172c60dc92c49685f5233482a327b1.jpg: 384x640 (no detections), 125.6ms\n",
            "image 84/222 /content/person_camera_security1-20/test/images/1689_person_jpg.rf.b6da213032f6a77b454dbd2821994eeb.jpg: 384x640 1 person, 138.4ms\n",
            "image 85/222 /content/person_camera_security1-20/test/images/1707_person_jpg.rf.3a5cb5aa44f9e8ba6b9e22f7c74cfb41.jpg: 384x640 1 person, 126.5ms\n",
            "image 86/222 /content/person_camera_security1-20/test/images/1738_person_jpg.rf.098fceebda05a56c3b47be9f856bde6b.jpg: 384x640 1 person, 1 cup, 125.9ms\n",
            "image 87/222 /content/person_camera_security1-20/test/images/173_person_jpg.rf.66ae6b4f61f4b4c78720e9d99f7d2545.jpg: 384x640 (no detections), 130.7ms\n",
            "image 88/222 /content/person_camera_security1-20/test/images/1745_person_jpg.rf.308e3c34ae1610c2b13aa1ebed4787dd.jpg: 384x640 1 person, 131.4ms\n",
            "image 89/222 /content/person_camera_security1-20/test/images/1774_person_jpg.rf.84dea4065a0c4adddd1d473881195653.jpg: 384x640 2 persons, 134.2ms\n",
            "image 90/222 /content/person_camera_security1-20/test/images/1776_person_jpg.rf.7a8a4468f8c344b18a19e7006e89d4ce.jpg: 384x640 1 person, 126.0ms\n",
            "image 91/222 /content/person_camera_security1-20/test/images/1778_person_jpg.rf.af1a0096d7a7195041749a2ac2245711.jpg: 384x640 1 umbrella, 127.8ms\n",
            "image 92/222 /content/person_camera_security1-20/test/images/1805_person_jpg.rf.d74d963586a9000754099457f0dc31ba.jpg: 384x640 (no detections), 309.2ms\n",
            "image 93/222 /content/person_camera_security1-20/test/images/1811_person_jpg.rf.89c0276af0bca90c17bfcd1ebec40b48.jpg: 384x640 (no detections), 527.6ms\n",
            "image 94/222 /content/person_camera_security1-20/test/images/1815_person_jpg.rf.d526f6aecec22b394840f66fee996bdc.jpg: 384x640 1 person, 278.9ms\n",
            "image 95/222 /content/person_camera_security1-20/test/images/1834_person_jpg.rf.a20486c9fa76c6099bb4fb599c189f37.jpg: 384x640 1 potted plant, 127.1ms\n",
            "image 96/222 /content/person_camera_security1-20/test/images/1837_person_jpg.rf.303d1e626d881536469c4245ffa6146d.jpg: 384x640 (no detections), 140.5ms\n",
            "image 97/222 /content/person_camera_security1-20/test/images/1840_person_jpg.rf.bf46e97a792495941a4f5b32a2658468.jpg: 384x640 1 person, 520.9ms\n",
            "image 98/222 /content/person_camera_security1-20/test/images/1843_person_jpg.rf.36c24b5b7d5306c9ee5c706c51267f52.jpg: 384x640 (no detections), 479.1ms\n",
            "image 99/222 /content/person_camera_security1-20/test/images/1845_person_jpg.rf.bd0eff40d73fc055964dbb2dec44cb27.jpg: 384x640 (no detections), 252.2ms\n",
            "image 100/222 /content/person_camera_security1-20/test/images/1851_person_jpg.rf.15e9b20753b1a15530334ddbedf14f83.jpg: 384x640 (no detections), 215.3ms\n",
            "image 101/222 /content/person_camera_security1-20/test/images/1859_person_jpg.rf.8b6dd741bf8978d1df7b62df258cf5dd.jpg: 384x640 1 person, 194.8ms\n",
            "image 102/222 /content/person_camera_security1-20/test/images/186_person_jpg.rf.6cc1a578d0d7c606e2b1272153696b88.jpg: 384x640 1 person, 141.8ms\n",
            "image 103/222 /content/person_camera_security1-20/test/images/1880_person_jpg.rf.a0773128805f41fad6ca0f57a5d9e759.jpg: 384x640 3 persons, 134.3ms\n",
            "image 104/222 /content/person_camera_security1-20/test/images/1883_person_jpg.rf.44cae69d6471cf5edc757789a45b54ce.jpg: 384x640 3 persons, 134.5ms\n",
            "image 105/222 /content/person_camera_security1-20/test/images/1ecfe8e0-5c68-11eb-8b40-be7fb69f1d58_jpg.rf.5af4ee5e8326f541df52e2c7b0d85f6e.jpg: 384x640 1 person, 127.4ms\n",
            "image 106/222 /content/person_camera_security1-20/test/images/210_person_jpg.rf.237441df3dab09b09ff4e91395dcb5bf.jpg: 384x640 1 car, 135.4ms\n",
            "image 107/222 /content/person_camera_security1-20/test/images/213_person_jpg.rf.1f4ea6fbbc79064cd9e04c26abc693c7.jpg: 384x640 2 persons, 130.5ms\n",
            "image 108/222 /content/person_camera_security1-20/test/images/215_person_jpg.rf.0fd501f61e546b509a8cace25c0ba9fb.jpg: 384x640 2 persons, 144.2ms\n",
            "image 109/222 /content/person_camera_security1-20/test/images/216_person_jpg.rf.3ce4913457304266deabb886ff65c874.jpg: 384x640 2 persons, 129.8ms\n",
            "image 110/222 /content/person_camera_security1-20/test/images/221_person_jpg.rf.79b25cc009a7b1bc3170cde16f1dc1ae.jpg: 384x640 1 person, 177.0ms\n",
            "image 111/222 /content/person_camera_security1-20/test/images/229_person_jpg.rf.5d6abc193938e8d721bc4b46d1e6eb19.jpg: 384x640 1 person, 1 car, 203.7ms\n",
            "image 112/222 /content/person_camera_security1-20/test/images/284_person_jpg.rf.c109a609e84b29d9d675935210bd5f93.jpg: 384x640 1 person, 208.6ms\n",
            "image 113/222 /content/person_camera_security1-20/test/images/286_person_jpg.rf.6dec0214a88b1906a9ea5f6f9fb3ef3f.jpg: 384x640 (no detections), 208.5ms\n",
            "image 114/222 /content/person_camera_security1-20/test/images/28_person_jpg.rf.5fd53416377e856ec17802aa23d9ba36.jpg: 384x640 1 person, 202.0ms\n",
            "image 115/222 /content/person_camera_security1-20/test/images/291_person_jpg.rf.e6c5e03f364accb612a9c4ea3e1e8ad4.jpg: 384x640 1 person, 196.2ms\n",
            "image 116/222 /content/person_camera_security1-20/test/images/293_person_jpg.rf.f2a18749e641333b89b22f3f12274ec1.jpg: 384x640 1 person, 201.8ms\n",
            "image 117/222 /content/person_camera_security1-20/test/images/322_person_jpg.rf.10018cc28a9b2ebc030c378288fff301.jpg: 384x640 (no detections), 208.9ms\n",
            "image 118/222 /content/person_camera_security1-20/test/images/324_person_jpg.rf.8d99d67f5f212b6eb1412550a2138810.jpg: 384x640 1 person, 1 bottle, 221.7ms\n",
            "image 119/222 /content/person_camera_security1-20/test/images/32_person_jpg.rf.562410eb2406a3c6cbb364200178f48e.jpg: 384x640 1 person, 197.0ms\n",
            "image 120/222 /content/person_camera_security1-20/test/images/330_person_jpg.rf.0519ac7254e104e381376a48cae7e9d5.jpg: 384x640 1 person, 203.1ms\n",
            "image 121/222 /content/person_camera_security1-20/test/images/337_person_jpg.rf.a6060f3eaa961cf3e2c1fb6279b59513.jpg: 384x640 1 person, 1 bottle, 167.6ms\n",
            "image 122/222 /content/person_camera_security1-20/test/images/339_person_jpg.rf.7ccce6e17166c7872f91326e62f5957e.jpg: 384x640 (no detections), 129.0ms\n",
            "image 123/222 /content/person_camera_security1-20/test/images/347_person_jpg.rf.458a9f657c54f22a46f57dc516fab9d9.jpg: 384x640 1 person, 133.4ms\n",
            "image 124/222 /content/person_camera_security1-20/test/images/351_person_jpg.rf.f1867f2572632eb5b6a1a0cdccd3df34.jpg: 384x640 (no detections), 141.7ms\n",
            "image 125/222 /content/person_camera_security1-20/test/images/361_person_jpg.rf.7eadc6d2a53a6940cb616ecbcc88ab9d.jpg: 384x640 (no detections), 127.7ms\n",
            "image 126/222 /content/person_camera_security1-20/test/images/38_person_jpg.rf.c78bc0f493be5adf99658a206c8abfd4.jpg: 384x640 1 person, 127.1ms\n",
            "image 127/222 /content/person_camera_security1-20/test/images/396_person_jpg.rf.23325c3e88ec1db78a59471134e67229.jpg: 384x640 (no detections), 130.7ms\n",
            "image 128/222 /content/person_camera_security1-20/test/images/40_person_jpg.rf.7f780c94d09ff5618b2d42767fa580f7.jpg: 384x640 1 person, 128.7ms\n",
            "image 129/222 /content/person_camera_security1-20/test/images/421_person_jpg.rf.e65575b26b00e80b50037c612d92db28.jpg: 384x640 1 person, 1 chair, 130.5ms\n",
            "image 130/222 /content/person_camera_security1-20/test/images/428_person_jpg.rf.e5736b92e1f32efd85377282e06a010c.jpg: 384x640 (no detections), 132.3ms\n",
            "image 131/222 /content/person_camera_security1-20/test/images/430_person_jpg.rf.fd81c9b272196d1ffa64dfb4a95145ec.jpg: 384x640 (no detections), 147.6ms\n",
            "image 132/222 /content/person_camera_security1-20/test/images/43_person_jpg.rf.cbc606a948470d6936fa08b6d8330597.jpg: 384x640 1 person, 141.1ms\n",
            "image 133/222 /content/person_camera_security1-20/test/images/446_person_jpg.rf.e2e53299b2cb95290bf2f08610449f92.jpg: 384x640 (no detections), 132.3ms\n",
            "image 134/222 /content/person_camera_security1-20/test/images/450_person_jpg.rf.764c45192f4f5d9cb5ee990bf29aebb2.jpg: 384x640 (no detections), 126.6ms\n",
            "image 135/222 /content/person_camera_security1-20/test/images/456_person_jpg.rf.d0684bbc184d3161727a6b45bc050709.jpg: 384x640 1 person, 131.2ms\n",
            "image 136/222 /content/person_camera_security1-20/test/images/45_person_jpg.rf.4d91f0ed267585ba8635681b25cff3e4.jpg: 384x640 (no detections), 133.8ms\n",
            "image 137/222 /content/person_camera_security1-20/test/images/460_person_jpg.rf.6665517fa0f120a4c14d6973b536356f.jpg: 384x640 (no detections), 130.9ms\n",
            "image 138/222 /content/person_camera_security1-20/test/images/462_person_jpg.rf.281e6d0010aeaea93be68501e4c3355f.jpg: 384x640 (no detections), 139.6ms\n",
            "image 139/222 /content/person_camera_security1-20/test/images/513_png_jpg.rf.220a9d3613ec4c31212e6cf55a75b9d1.jpg: 640x640 (no detections), 222.8ms\n",
            "image 140/222 /content/person_camera_security1-20/test/images/528_person_jpg.rf.623066f9dad9e25a8b2093a36a74d199.jpg: 384x640 1 person, 131.0ms\n",
            "image 141/222 /content/person_camera_security1-20/test/images/52_person_jpg.rf.d3317857888eff7c8485a19fb48a1d04.jpg: 384x640 (no detections), 136.2ms\n",
            "image 142/222 /content/person_camera_security1-20/test/images/537_person_jpg.rf.9d40fa504ab401c045ba26a1410ee6c2.jpg: 384x640 2 persons, 125.9ms\n",
            "image 143/222 /content/person_camera_security1-20/test/images/568_person_jpg.rf.5d682d24d6f1ee9e89335eb780697066.jpg: 384x640 1 person, 129.3ms\n",
            "image 144/222 /content/person_camera_security1-20/test/images/58_person_jpg.rf.5aab23c8be9b54e970fbc39fff4eb7bb.jpg: 384x640 (no detections), 127.9ms\n",
            "image 145/222 /content/person_camera_security1-20/test/images/594_person_jpg.rf.6ad8db0acdbc1aa9a7830f0fbec97a6a.jpg: 384x640 (no detections), 131.2ms\n",
            "image 146/222 /content/person_camera_security1-20/test/images/595_person_jpg.rf.a9f3a73fbf8efd2cf8b39e8e7dfbb77f.jpg: 384x640 (no detections), 127.6ms\n",
            "image 147/222 /content/person_camera_security1-20/test/images/59_person_jpg.rf.6046687b6c30813b158077ad08ec7a0c.jpg: 384x640 1 person, 127.7ms\n",
            "image 148/222 /content/person_camera_security1-20/test/images/5_person_jpg.rf.efee17b1c3a83a861fc4785fd46a35a2.jpg: 384x640 (no detections), 129.7ms\n",
            "image 149/222 /content/person_camera_security1-20/test/images/612_person_jpg.rf.622cbdee895e4d2ba4636b68b8d1e8b3.jpg: 384x640 1 bowl, 122.0ms\n",
            "image 150/222 /content/person_camera_security1-20/test/images/613_person_jpg.rf.a4e2d084d6c83bac2d2421ad50b240f0.jpg: 384x640 (no detections), 123.5ms\n",
            "image 151/222 /content/person_camera_security1-20/test/images/615_person_jpg.rf.fec090ac09f4a0a09a61cfe365232525.jpg: 384x640 (no detections), 119.4ms\n",
            "image 152/222 /content/person_camera_security1-20/test/images/624_person_jpg.rf.4d1456db6835212361e1af0c0c32851f.jpg: 384x640 (no detections), 140.5ms\n",
            "image 153/222 /content/person_camera_security1-20/test/images/625_person_jpg.rf.71ee2b2daf0c1be0cd7b4123f666bedc.jpg: 384x640 1 car, 129.7ms\n",
            "image 154/222 /content/person_camera_security1-20/test/images/643_person_jpg.rf.6e5228f136b8e9edbfcff9f2323a7e0e.jpg: 384x640 1 bowl, 128.1ms\n",
            "image 155/222 /content/person_camera_security1-20/test/images/648_person_jpg.rf.17d4a48641ee61e19d01ea39976a6481.jpg: 384x640 1 bowl, 129.6ms\n",
            "image 156/222 /content/person_camera_security1-20/test/images/65_person_jpg.rf.577a958905b753f3d9b9f96f6f49b82b.jpg: 384x640 (no detections), 131.0ms\n",
            "image 157/222 /content/person_camera_security1-20/test/images/665_person_jpg.rf.b32f94b3fd179003906e147a3cf502c4.jpg: 384x640 1 bowl, 124.9ms\n",
            "image 158/222 /content/person_camera_security1-20/test/images/684_person_jpg.rf.9cd5d1cad4ec2a68ccacce95f6af48d3.jpg: 384x640 1 bowl, 123.2ms\n",
            "image 159/222 /content/person_camera_security1-20/test/images/6_person_jpg.rf.b471a2b81769c7c083a56e8ebdbd7dc3.jpg: 384x640 (no detections), 144.0ms\n",
            "image 160/222 /content/person_camera_security1-20/test/images/700_person_jpg.rf.d24a5cc95762b5085dd14c4c07e33a89.jpg: 384x640 (no detections), 127.2ms\n",
            "image 161/222 /content/person_camera_security1-20/test/images/706_person_jpg.rf.a3a6992018293df082f8bdc9e7da5ff9.jpg: 384x640 (no detections), 138.0ms\n",
            "image 162/222 /content/person_camera_security1-20/test/images/722_person_jpg.rf.45c6d626eb90f13068ffdc39392ba1ae.jpg: 384x640 1 bowl, 131.4ms\n",
            "image 163/222 /content/person_camera_security1-20/test/images/732_person_jpg.rf.eafb63a22f442ea79e4742b39333be6d.jpg: 384x640 (no detections), 138.7ms\n",
            "image 164/222 /content/person_camera_security1-20/test/images/741_person_jpg.rf.1835ed07be4543870f3153068e6c0d00.jpg: 384x640 4 persons, 125.5ms\n",
            "image 165/222 /content/person_camera_security1-20/test/images/743_person_jpg.rf.2efbec5cc6dd9edc2a536dbb940d53f8.jpg: 384x640 2 persons, 126.5ms\n",
            "image 166/222 /content/person_camera_security1-20/test/images/745_person_jpg.rf.1d6f00e7ab5dc62516fb0375c422ff39.jpg: 384x640 3 persons, 139.8ms\n",
            "image 167/222 /content/person_camera_security1-20/test/images/74_person_jpg.rf.7b147fce9fff8b79acb6f01a6db4873d.jpg: 384x640 1 truck, 127.1ms\n",
            "image 168/222 /content/person_camera_security1-20/test/images/755_person_jpg.rf.4eb90f2938fa67990f882a0c5043dec4.jpg: 384x640 (no detections), 132.7ms\n",
            "image 169/222 /content/person_camera_security1-20/test/images/788_person_jpg.rf.7d4401868132780aabe71cdb8e0824ee.jpg: 384x640 1 bowl, 129.2ms\n",
            "image 170/222 /content/person_camera_security1-20/test/images/793_person_jpg.rf.6d2155285ea9872e4b96ef7f76ba4517.jpg: 384x640 (no detections), 128.0ms\n",
            "image 171/222 /content/person_camera_security1-20/test/images/796_person_jpg.rf.3e8e256f02421dde8edcb4aa55efe6d8.jpg: 384x640 1 car, 133.0ms\n",
            "image 172/222 /content/person_camera_security1-20/test/images/798_person_jpg.rf.eb37c5d026906de307755ec2d59626a0.jpg: 384x640 (no detections), 127.7ms\n",
            "image 173/222 /content/person_camera_security1-20/test/images/800_person_jpg.rf.bcd7c5e3b0160d92113e71834261a84a.jpg: 384x640 1 bowl, 133.7ms\n",
            "image 174/222 /content/person_camera_security1-20/test/images/95_person_jpg.rf.d54b2cc29b50322ac1f100925219f6ce.jpg: 384x640 1 person, 156.9ms\n",
            "image 175/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_38-1-_mp4-75_jpg.rf.e48c3507c5a0fc56ba9fac02106469ae.jpg: 352x640 9 persons, 1 car, 134.0ms\n",
            "image 176/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_39-1-_mp4-51_jpg.rf.c9c354fc693a5a391f32e668ec858092.jpg: 352x640 11 persons, 118.3ms\n",
            "image 177/222 /content/person_camera_security1-20/test/images/WhatsApp-Video-2022-03-23-at-10_07_39-1-_mp4-72_jpg.rf.39eba7b7db33bccced9cd55fdd2e578a.jpg: 352x640 9 persons, 1 car, 116.3ms\n",
            "image 178/222 /content/person_camera_security1-20/test/images/crop_1420_jpg.rf.0bdf2ef5bd7ef3c1bb58f21002b53f48.jpg: 640x640 5 persons, 1 dog, 234.3ms\n",
            "image 179/222 /content/person_camera_security1-20/test/images/crop_2394_jpg.rf.28443e1ef476c4133c8eca021cf0831a.jpg: 640x640 8 persons, 224.4ms\n",
            "image 180/222 /content/person_camera_security1-20/test/images/crop_242_jpg.rf.a8a30fa9f7846e04d39c8e432115fe43.jpg: 640x640 11 persons, 211.3ms\n",
            "image 181/222 /content/person_camera_security1-20/test/images/crop_4039_jpg.rf.7af4f2bd80021242d162f036c1a01ed1.jpg: 640x640 2 persons, 1 bird, 212.9ms\n",
            "image 182/222 /content/person_camera_security1-20/test/images/crop_4137_jpg.rf.5ad2d80b2c79aa3d52573086d93cda2a.jpg: 640x640 1 person, 1 bird, 1 skateboard, 207.1ms\n",
            "image 183/222 /content/person_camera_security1-20/test/images/oz_frame557_jpg.rf.9fa3b1db4225e6fd3951458ba88f4065.jpg: 384x640 2 persons, 125.5ms\n",
            "image 184/222 /content/person_camera_security1-20/test/images/person_100_jpg.rf.07f804bebbbec9448413ed52a4222277.jpg: 384x640 8 persons, 1 handbag, 133.9ms\n",
            "image 185/222 /content/person_camera_security1-20/test/images/person_112_jpg.rf.d8797604dcfcbefeca2a3175ee22fe47.jpg: 384x640 8 persons, 137.5ms\n",
            "image 186/222 /content/person_camera_security1-20/test/images/person_124_jpg.rf.332ec575863a56062d7183cc80d1697c.jpg: 384x640 8 persons, 2 handbags, 133.4ms\n",
            "image 187/222 /content/person_camera_security1-20/test/images/person_13_jpg.rf.442a83621cd600428a7312b10110119d.jpg: 384x640 9 persons, 124.1ms\n",
            "image 188/222 /content/person_camera_security1-20/test/images/person_21_jpg.rf.3960312b631c2268f9500eadf91fc516.jpg: 384x640 7 persons, 215.5ms\n",
            "image 189/222 /content/person_camera_security1-20/test/images/person_53_jpg.rf.704a1bda3ce3c415e18237f26c67194e.jpg: 384x640 11 persons, 202.7ms\n",
            "image 190/222 /content/person_camera_security1-20/test/images/person_62_jpg.rf.0abef9e66df5902c35ca9eee58d4d146.jpg: 384x640 9 persons, 212.3ms\n",
            "image 191/222 /content/person_camera_security1-20/test/images/person_63_jpg.rf.0e5314e067f3a45e78b73027ffe90727.jpg: 384x640 8 persons, 198.8ms\n",
            "image 192/222 /content/person_camera_security1-20/test/images/person_64_jpg.rf.0cc55810301e50e200f4c192e3474a9b.jpg: 384x640 9 persons, 196.0ms\n",
            "image 193/222 /content/person_camera_security1-20/test/images/person_79_jpg.rf.0e49a1064cf0360fb62019c50bb5d7dd.jpg: 384x640 6 persons, 195.5ms\n",
            "image 194/222 /content/person_camera_security1-20/test/images/person_85_jpg.rf.2cfa372a981d478b66d11e4f6462a66a.jpg: 384x640 7 persons, 213.1ms\n",
            "image 195/222 /content/person_camera_security1-20/test/images/person_89_jpg.rf.33f7e903771a44538f0849846cf286bf.jpg: 384x640 8 persons, 209.8ms\n",
            "image 196/222 /content/person_camera_security1-20/test/images/point01_39_png_jpg.rf.0b8ccd0da46fe7029e5e62fdd34d5b9e.jpg: 384x640 4 persons, 2 chairs, 1 dining table, 210.0ms\n",
            "image 197/222 /content/person_camera_security1-20/test/images/point01_441_png_jpg.rf.29b3994e3e39c4cfefec78da828c2730.jpg: 384x640 2 persons, 203.2ms\n",
            "image 198/222 /content/person_camera_security1-20/test/images/point01_679_png_jpg.rf.a950046ad35ccea107c4fbf36a4b7a37.jpg: 384x640 2 persons, 216.8ms\n",
            "image 199/222 /content/person_camera_security1-20/test/images/point02_223_png_jpg.rf.c5bfd9a0d91214be91097cb80b875db1.jpg: 384x640 3 persons, 1 couch, 1 tv, 133.4ms\n",
            "image 200/222 /content/person_camera_security1-20/test/images/point02_438_png_jpg.rf.2a8477e3534dffd2017729c85b5ac9c3.jpg: 384x640 2 persons, 1 couch, 3 tvs, 141.7ms\n",
            "image 201/222 /content/person_camera_security1-20/test/images/point02_93_png_jpg.rf.d0a80566cb306cdd1b84978fe6e97136.jpg: 384x640 1 person, 1 couch, 1 tv, 137.7ms\n",
            "image 202/222 /content/person_camera_security1-20/test/images/point03_113_png_jpg.rf.d5a0b6065ce1bab7dadd675a3760def2.jpg: 384x640 1 person, 1 chair, 128.6ms\n",
            "image 203/222 /content/person_camera_security1-20/test/images/point03_33_png_jpg.rf.0f99f5210b09aad4fefbcd8c9f5ac894.jpg: 384x640 1 person, 1 chair, 133.1ms\n",
            "image 204/222 /content/person_camera_security1-20/test/images/point03_51_png_jpg.rf.d076ec29dd130505be8446b86cf6eccc.jpg: 384x640 2 persons, 1 skateboard, 1 chair, 132.1ms\n",
            "image 205/222 /content/person_camera_security1-20/test/images/point03_65_png_jpg.rf.cac6fb2629262f3ab912c27ddadd8eb6.jpg: 384x640 1 person, 1 chair, 137.4ms\n",
            "image 206/222 /content/person_camera_security1-20/test/images/point03_95_png_jpg.rf.b5b7d70a2d781118781709903c621eab.jpg: 384x640 1 person, 1 skateboard, 148.1ms\n",
            "image 207/222 /content/person_camera_security1-20/test/images/point04_185_png_jpg.rf.23ef4b46adc7e00494040d26b4e20cf9.jpg: 384x640 2 persons, 1 chair, 141.9ms\n",
            "image 208/222 /content/person_camera_security1-20/test/images/point04_215_png_jpg.rf.6c37c73bad8674f20f266556fba8084d.jpg: 384x640 2 persons, 1 chair, 134.6ms\n",
            "image 209/222 /content/person_camera_security1-20/test/images/point04_254_png_jpg.rf.8e51494dbd94b28bdb76826f193d1283.jpg: 384x640 1 person, 1 chair, 135.6ms\n",
            "image 210/222 /content/person_camera_security1-20/test/images/point04_275_png_jpg.rf.781e7b0752fad974b7be44f7d339f9c7.jpg: 384x640 2 persons, 1 chair, 1 laptop, 130.9ms\n",
            "image 211/222 /content/person_camera_security1-20/test/images/point04_294_png_jpg.rf.c3ce6ffe45bfcfefd94f8bd44c3516c7.jpg: 384x640 1 person, 1 chair, 136.9ms\n",
            "image 212/222 /content/person_camera_security1-20/test/images/point04_326_png_jpg.rf.5f38a472e4338f74f383cfb4f8cff08e.jpg: 384x640 2 persons, 131.5ms\n",
            "image 213/222 /content/person_camera_security1-20/test/images/point04_354_png_jpg.rf.0303ba3f983db1c6b4801763a5e7c367.jpg: 384x640 2 persons, 128.5ms\n",
            "image 214/222 /content/person_camera_security1-20/test/images/point04_573_png_jpg.rf.f62780af0eb9d3e032a169a1538ac34a.jpg: 384x640 2 persons, 1 chair, 140.2ms\n",
            "image 215/222 /content/person_camera_security1-20/test/images/point05_166_png_jpg.rf.2cfd7ae224a7d02ed9821176896cb7f7.jpg: 384x640 1 person, 132.5ms\n",
            "image 216/222 /content/person_camera_security1-20/test/images/point05_201_png_jpg.rf.abc663b3c368225bd89d5463c665e193.jpg: 384x640 1 person, 129.4ms\n",
            "image 217/222 /content/person_camera_security1-20/test/images/point05_3_png_jpg.rf.98c608c3a9257150c9d689fd29372021.jpg: 384x640 2 persons, 134.0ms\n",
            "image 218/222 /content/person_camera_security1-20/test/images/point05_57_png_jpg.rf.16fa9cbc75d1513b02921ec0449d6c48.jpg: 384x640 1 person, 141.9ms\n",
            "image 219/222 /content/person_camera_security1-20/test/images/point06_221_png_jpg.rf.4349c58dadc88d6228203ebffdc8cab1.jpg: 384x640 1 person, 1 suitcase, 6 chairs, 4 tvs, 3 laptops, 128.4ms\n",
            "image 220/222 /content/person_camera_security1-20/test/images/point06_23_png_jpg.rf.e77b42475e34d0c4063d6d4b6a5de15b.jpg: 384x640 1 person, 6 chairs, 3 tvs, 2 laptops, 128.0ms\n",
            "image 221/222 /content/person_camera_security1-20/test/images/point06_302_png_jpg.rf.bb0defeb14cb58f465e1f108c03f4f58.jpg: 384x640 1 person, 1 suitcase, 3 chairs, 2 tvs, 3 laptops, 129.6ms\n",
            "image 222/222 /content/person_camera_security1-20/test/images/point06_69_png_jpg.rf.3c2da00c11bf29e4bd7e467c13791b3a.jpg: 384x640 1 person, 5 chairs, 2 tvs, 3 laptops, 129.0ms\n",
            "Speed: 2.0ms preprocess, 154.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "T1XUaw9arLTK",
        "outputId": "d063b86b-7974-411d-b850-59dcd1730ae7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [484, 492]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-279975415a3c>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Calculate metrics for default model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprecision_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_default_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mrecall_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_default_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0maccuracy_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_default_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1952\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \"\"\"\n\u001b[0;32m-> 1954\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1955\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [484, 492]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}